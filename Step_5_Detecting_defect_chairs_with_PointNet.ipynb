{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "94ca549715404c7c86e1bb5b02483f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_035be468f0c74fd9ba46e51bf6bddec7",
              "IPY_MODEL_0ab37b579fba40b3be0f68e5c7f82a79",
              "IPY_MODEL_1bd674000a1f498399897475d5783520",
              "IPY_MODEL_d5ee05c9d3bd46ae8ba9b48d2f3d3cd5",
              "IPY_MODEL_758fe1c97b344293a05cafbb3534f108"
            ],
            "layout": "IPY_MODEL_93d8e22c8e144611a917511c8920c409",
            "tabbable": null,
            "tooltip": null
          }
        },
        "035be468f0c74fd9ba46e51bf6bddec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_cc7c899dbd644024a3998ca342c0fd99",
            "placeholder": "​",
            "style": "IPY_MODEL_5b6dad74c1c048dca1695c5f1eb9df60",
            "tabbable": null,
            "tooltip": null,
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "0ab37b579fba40b3be0f68e5c7f82a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_allow_html": false,
            "disabled": false,
            "layout": "IPY_MODEL_8bcb260ad6804feaa8b50d793646b572",
            "placeholder": "​",
            "style": "IPY_MODEL_070b4765947f44e9aa0b1730da31597c",
            "tabbable": null,
            "tooltip": null,
            "value": ""
          }
        },
        "1bd674000a1f498399897475d5783520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_allow_html": false,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_60a843208fa84d4ea390afcd8f00abcd",
            "style": "IPY_MODEL_267d8acbf6d64b3d8608f345de9a04d5",
            "tabbable": null,
            "tooltip": null,
            "value": true
          }
        },
        "d5ee05c9d3bd46ae8ba9b48d2f3d3cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_3b669181ed424872962cc6c97882cd29",
            "style": "IPY_MODEL_0d3c141afd674eefa4d3ab6206373a3d",
            "tabbable": null,
            "tooltip": null
          }
        },
        "758fe1c97b344293a05cafbb3534f108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_5efda927db21420f88d2678095eac4cf",
            "placeholder": "​",
            "style": "IPY_MODEL_91c01b1ceeb2456399bb3db0fbe29175",
            "tabbable": null,
            "tooltip": null,
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "93d8e22c8e144611a917511c8920c409": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "cc7c899dbd644024a3998ca342c0fd99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b6dad74c1c048dca1695c5f1eb9df60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "8bcb260ad6804feaa8b50d793646b572": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "070b4765947f44e9aa0b1730da31597c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "TextStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "60a843208fa84d4ea390afcd8f00abcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "267d8acbf6d64b3d8608f345de9a04d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "CheckboxStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": ""
          }
        },
        "3b669181ed424872962cc6c97882cd29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d3c141afd674eefa4d3ab6206373a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_family": null,
            "font_size": null,
            "font_style": null,
            "font_variant": null,
            "font_weight": null,
            "text_color": null,
            "text_decoration": null
          }
        },
        "5efda927db21420f88d2678095eac4cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91c01b1ceeb2456399bb3db0fbe29175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "9ba44b572c8b41f8b947ae053c9d0cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5af95cfe91234e798e16c80d8570e41e",
              "IPY_MODEL_3a55031398f94c44b827b49566c95874",
              "IPY_MODEL_4654f26be0ee498494885313c6308517"
            ],
            "layout": "IPY_MODEL_f0f42743f1014068863706c760c4daa9",
            "tabbable": null,
            "tooltip": null
          }
        },
        "5af95cfe91234e798e16c80d8570e41e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_b97db2dca6d5478d9f7d0419a86a5f8e",
            "placeholder": "​",
            "style": "IPY_MODEL_8c063ce8e91c4753a2140d21ff69317c",
            "tabbable": null,
            "tooltip": null,
            "value": "model.pt: 100%"
          }
        },
        "3a55031398f94c44b827b49566c95874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_252f772a0a3e462ea1a498943f5669c2",
            "max": 388091433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13a42341a48b495b8360e3df4ad2c661",
            "tabbable": null,
            "tooltip": null,
            "value": 388091433
          }
        },
        "4654f26be0ee498494885313c6308517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_2e77b15866a545858cca45e627cf6e31",
            "placeholder": "​",
            "style": "IPY_MODEL_f5867a63bbd54325b0797447632eb5f3",
            "tabbable": null,
            "tooltip": null,
            "value": " 388M/388M [00:08&lt;00:00, 46.7MB/s]"
          }
        },
        "f0f42743f1014068863706c760c4daa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b97db2dca6d5478d9f7d0419a86a5f8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c063ce8e91c4753a2140d21ff69317c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "252f772a0a3e462ea1a498943f5669c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13a42341a48b495b8360e3df4ad2c661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e77b15866a545858cca45e627cf6e31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5867a63bbd54325b0797447632eb5f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "315163fa3c974f23b2a54aab7e3037c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4f2cb5a7d1b4de2be02d398c613b57b",
              "IPY_MODEL_86077b4dacb7496d8b660b4d42cba49e",
              "IPY_MODEL_5b42532e3ace46e68ada1b1f216db7b6"
            ],
            "layout": "IPY_MODEL_0601abf594964e2f91fbcd25fe1dc692",
            "tabbable": null,
            "tooltip": null
          }
        },
        "c4f2cb5a7d1b4de2be02d398c613b57b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_a119d9c67a934b208a80bee37063db9a",
            "placeholder": "​",
            "style": "IPY_MODEL_83645d5001c948e0ba3d1a3fcfe0c10d",
            "tabbable": null,
            "tooltip": null,
            "value": ""
          }
        },
        "86077b4dacb7496d8b660b4d42cba49e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_985c051a5dc640b2a6ef7fee3417f078",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c1d1a10fecd4ba2884018188c73c8fa",
            "tabbable": null,
            "tooltip": null,
            "value": 0
          }
        },
        "5b42532e3ace46e68ada1b1f216db7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_ad2f21d38f11401397e89ac77a729d00",
            "placeholder": "​",
            "style": "IPY_MODEL_4b6718923d544cf0a263792a865a2e6d",
            "tabbable": null,
            "tooltip": null,
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "0601abf594964e2f91fbcd25fe1dc692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a119d9c67a934b208a80bee37063db9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83645d5001c948e0ba3d1a3fcfe0c10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "985c051a5dc640b2a6ef7fee3417f078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2c1d1a10fecd4ba2884018188c73c8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad2f21d38f11401397e89ac77a729d00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b6718923d544cf0a263792a865a2e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook for the extension of the project\n",
        "\n",
        "This note book is the extension part of the project of the cource Advanced Machine Learning teached at Politecnico di Torino.\n",
        "\n",
        "In this notebook we create a simulated a real-life application of quality control in a production line. The products that are in distribution are products that are produced correctly. While products that are out of distribution is assumed to be defect.\n",
        "\n",
        "We used code and data from the 3DOS paper and the OpenShape paper\n",
        "\n",
        "Open shape:\n",
        "@misc{liu2023openshape,\n",
        "      title={OpenShape: Scaling Up 3D Shape Representation Towards Open-World Understanding},\n",
        "      author={Minghua Liu and Ruoxi Shi and Kaiming Kuang and Yinhao Zhu and Xuanlin Li and Shizhong Han and Hong Cai and Fatih Porikli and Hao Su},\n",
        "      year={2023},\n",
        "      eprint={2305.10764},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.CV}\n",
        "}\n",
        "\n",
        "3DOS:\n",
        "@inproceedings{\n",
        "alliegro2022towards,\n",
        "title={Towards Open Set 3D Learning: Benchmarking and Understanding Semantic Novelty Detection on Pointclouds},\n",
        "author={Antonio Alliegro and Francesco Cappio Borlino and Tatiana Tommasi},\n",
        "booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},\n",
        "year={2022},\n",
        "url={https://openreview.net/forum?id=X2dHozbd1at}\n",
        "}"
      ],
      "metadata": {
        "id": "9teFaLRdlp5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone git repos to environment"
      ],
      "metadata": {
        "id": "W_I1PHBrhadT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git clone https://github.com/Colin97/OpenShape_code.git\n",
        "# Make sure you have git-lfs installed (https://git-lfs.com)\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/spaces/OpenShape/openshape-demo\n",
        "\n",
        "# if you want to clone without large files – just their pointers\n",
        "# prepend your git clone with the following env var:\n",
        "!GIT_LFS_SKIP_SMUDGE=1\n",
        "#!pip install -e .\n",
        "!git clone https://huggingface.co/OpenShape/openshape-demo-support\n"
      ],
      "metadata": {
        "id": "i2PTprijZ5vV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e99acc9-29e9-49dc-df67-998a962c8606"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'OpenShape_code'...\n",
            "remote: Enumerating objects: 119, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 119 (delta 31), reused 12 (delta 12), pack-reused 80\u001b[K\n",
            "Receiving objects: 100% (119/119), 3.45 MiB | 24.39 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n",
            "Git LFS initialized.\n",
            "Cloning into 'openshape-demo'...\n",
            "remote: Enumerating objects: 188, done.\u001b[K\n",
            "remote: Total 188 (delta 0), reused 0 (delta 0), pack-reused 188\u001b[K\n",
            "Receiving objects: 100% (188/188), 1.43 MiB | 12.76 MiB/s, done.\n",
            "Resolving deltas: 100% (85/85), done.\n",
            "Cloning into 'openshape-demo-support'...\n",
            "remote: Enumerating objects: 102, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 102 (delta 9), reused 0 (delta 0), pack-reused 83\u001b[K\n",
            "Receiving objects: 100% (102/102), 28.53 KiB | 14.26 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies\n",
        "Most dependencies are already satisfied by default in google colab"
      ],
      "metadata": {
        "id": "Jw-TaS50jZlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub wandb omegaconf torch_redstone einops tqdm open3d dgl timm\n",
        "!pip install --upgrade https://github.com/unlimblue/KNN_CUDA/releases/download/0.2/KNN_CUDA-0.2-py3-none-any.whl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4PSbBCbC26vP",
        "outputId": "45bd1414-7c3b-4cf5-c25b-9375e9d6be40"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.16.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_redstone\n",
            "  Downloading torch.redstone-0.0.5-py3-none-any.whl (18 kB)\n",
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Collecting open3d\n",
            "  Downloading open3d-0.18.0-cp310-cp310-manylinux_2_27_x86_64.whl (399.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dgl\n",
            "  Downloading dgl-1.1.3-cp310-cp310-manylinux1_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm\n",
            "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.40.5-py2.py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.5/258.5 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_redstone) (1.25.2)\n",
            "Collecting dash>=2.6.0 (from open3d)\n",
            "  Downloading dash-2.15.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.0.1)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (5.9.2)\n",
            "Collecting configargparse (from open3d)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from open3d)\n",
            "  Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from open3d)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (9.4.0)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.2.2)\n",
            "Collecting pyquaternion (from open3d)\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu121)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.2)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.2.5)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.15.0)\n",
            "Collecting dash-html-components==2.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting dash-table==5.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Collecting retrying (from dash>=2.6.0->open3d)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (7.0.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting comm>=0.1.3 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading comm-0.2.1-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.10 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyterlab-widgets~=3.0.10 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (3.2.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=2.2.3->open3d) (2.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (2.1.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.17.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.2.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.17.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat>=5.7.0->open3d) (4.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=c3fda3afd71044a63af91d622ffa3c1494a1862369bc60e86f25524f15da9210\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: dash-table, dash-html-components, dash-core-components, antlr4-python3-runtime, addict, widgetsnbextension, torch_redstone, smmap, setproctitle, sentry-sdk, retrying, pyquaternion, omegaconf, jedi, einops, docker-pycreds, configargparse, comm, gitdb, dgl, ipywidgets, GitPython, dash, wandb, timm, open3d\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.6\n",
            "    Uninstalling widgetsnbextension-3.6.6:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.6\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed GitPython-3.1.42 addict-2.4.0 antlr4-python3-runtime-4.9.3 comm-0.2.1 configargparse-1.7 dash-2.15.0 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 dgl-1.1.3 docker-pycreds-0.4.0 einops-0.7.0 gitdb-4.0.11 ipywidgets-8.1.2 jedi-0.19.1 omegaconf-2.3.0 open3d-0.18.0 pyquaternion-0.9.9 retrying-1.3.4 sentry-sdk-1.40.5 setproctitle-1.3.3 smmap-5.0.1 timm-0.9.12 torch_redstone-0.0.5 wandb-0.16.3 widgetsnbextension-4.0.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting KNN-CUDA==0.2\n",
            "  Downloading https://github.com/unlimblue/KNN_CUDA/releases/download/0.2/KNN_CUDA-0.2-py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from KNN-CUDA==0.2) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from KNN-CUDA==0.2) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from KNN-CUDA==0.2) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->KNN-CUDA==0.2) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->KNN-CUDA==0.2) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->KNN-CUDA==0.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->KNN-CUDA==0.2) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->KNN-CUDA==0.2) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->KNN-CUDA==0.2) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->KNN-CUDA==0.2) (2.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->KNN-CUDA==0.2) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->KNN-CUDA==0.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->KNN-CUDA==0.2) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->KNN-CUDA==0.2) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->KNN-CUDA==0.2) (1.3.0)\n",
            "Installing collected packages: KNN-CUDA\n",
            "Successfully installed KNN-CUDA-0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Log in to Huggingface"
      ],
      "metadata": {
        "id": "AWm2jCYYxBhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "3TLMaekmxBPp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "id": "nmYWjzhrZxF6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "94ca549715404c7c86e1bb5b02483f38",
            "035be468f0c74fd9ba46e51bf6bddec7",
            "0ab37b579fba40b3be0f68e5c7f82a79",
            "1bd674000a1f498399897475d5783520",
            "d5ee05c9d3bd46ae8ba9b48d2f3d3cd5",
            "758fe1c97b344293a05cafbb3534f108",
            "93d8e22c8e144611a917511c8920c409",
            "cc7c899dbd644024a3998ca342c0fd99",
            "5b6dad74c1c048dca1695c5f1eb9df60",
            "8bcb260ad6804feaa8b50d793646b572",
            "070b4765947f44e9aa0b1730da31597c",
            "60a843208fa84d4ea390afcd8f00abcd",
            "267d8acbf6d64b3d8608f345de9a04d5",
            "3b669181ed424872962cc6c97882cd29",
            "0d3c141afd674eefa4d3ab6206373a3d",
            "5efda927db21420f88d2678095eac4cf",
            "91c01b1ceeb2456399bb3db0fbe29175"
          ]
        },
        "outputId": "615ee922-15a4-4a3d-91fa-95c6faa8236b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94ca549715404c7c86e1bb5b02483f38"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the OpenShape model from Huggingface"
      ],
      "metadata": {
        "id": "EmFurYFiyCSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/openshape-demo-support\n",
        "!pip install -e .\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "_-UugGsGiumt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4978d511-b129-4982-f7f4-02857336d2ba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/openshape-demo-support\n",
            "Obtaining file:///content/openshape-demo-support\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: openshape\n",
            "  Running setup.py develop for openshape\n",
            "Successfully installed openshape-0.1\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openshape\n",
        "model = openshape.load_pc_encoder('openshape-pointbert-vitg14-rgb')\n",
        "\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "21n-SAviizUw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9ba44b572c8b41f8b947ae053c9d0cba",
            "5af95cfe91234e798e16c80d8570e41e",
            "3a55031398f94c44b827b49566c95874",
            "4654f26be0ee498494885313c6308517",
            "f0f42743f1014068863706c760c4daa9",
            "b97db2dca6d5478d9f7d0419a86a5f8e",
            "8c063ce8e91c4753a2140d21ff69317c",
            "252f772a0a3e462ea1a498943f5669c2",
            "13a42341a48b495b8360e3df4ad2c661",
            "2e77b15866a545858cca45e627cf6e31",
            "f5867a63bbd54325b0797447632eb5f3"
          ]
        },
        "outputId": "e28ebbaa-5eeb-4fd0-ac83-15ae39b179ab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.pt:   0%|          | 0.00/388M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ba44b572c8b41f8b947ae053c9d0cba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Projected(\n",
              "  (ppat): PointPatchTransformer(\n",
              "    (sa): PointNetSetAbstraction(\n",
              "      (mlp_convs): ModuleList(\n",
              "        (0): Conv2d(9, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (mlp_bns): ModuleList(\n",
              "        (0-1): 2 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (lift): Sequential(\n",
              "      (0): Conv1d(259, 512, kernel_size=(1,), stride=(1,))\n",
              "      (1): Lambda()\n",
              "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x ModuleList(\n",
              "          (0): PreNorm(\n",
              "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (fn): Attention(\n",
              "              (attend): Softmax(dim=-1)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
              "              (to_out): Sequential(\n",
              "                (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "                (1): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): PreNorm(\n",
              "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (fn): FeedForward(\n",
              "              (net): Sequential(\n",
              "                (0): Linear(in_features=512, out_features=1536, bias=True)\n",
              "                (1): GELU(approximate='none')\n",
              "                (2): Dropout(p=0.0, inplace=False)\n",
              "                (3): Linear(in_features=1536, out_features=512, bias=True)\n",
              "                (4): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (proj): Linear(in_features=512, out_features=1280, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for fitting pointclouds to input dimentions for OpenShape"
      ],
      "metadata": {
        "id": "W0YW3xqHyJDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import random\n",
        "import torch\n",
        "from OpenShape_code.src.utils.data import normalize_pc\n",
        "\n",
        "def load_ply(file_name, num_points=10000, y_up=True):\n",
        "    pcd = o3d.io.read_point_cloud(file_name)  # Read the point cloud\n",
        "    xyz = np.asarray(pcd.points)  # Get xyz coordinates\n",
        "    rgb = np.asarray(pcd.colors)  # Get rgb colors\n",
        "    n = xyz.shape[0]\n",
        "\n",
        "    # Sample num_points points if necessary\n",
        "    if n > num_points:\n",
        "        idx = random.sample(range(n), num_points)\n",
        "        xyz = xyz[idx]\n",
        "        rgb = rgb[idx]\n",
        "    elif n < num_points:\n",
        "        print(f\"Warning: requested {num_points} points, but file has only {n} points.\", file=sys.stderr)\n",
        "\n",
        "    # Adjust orientation by swapping y and z if requested\n",
        "    if y_up:\n",
        "        xyz[:, [1, 2]] = xyz[:, [2, 1]]\n",
        "\n",
        "    # Normalize the point cloud coordinates\n",
        "    xyz_normalized = normalize_pc(xyz)\n",
        "\n",
        "    # Handle cases where rgb might be missing\n",
        "    if rgb.size == 0:\n",
        "        rgb = np.ones_like(xyz_normalized) * 0.4  # Default to a constant color if missing\n",
        "\n",
        "    # Concatenate xyz with rgb\n",
        "    features = np.concatenate([xyz_normalized, rgb], axis=1)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    xyz_tensor = torch.from_numpy(xyz_normalized).float()\n",
        "    features_tensor = torch.from_numpy(features).float()\n",
        "\n",
        "    # Add batch dimention to fit as single input to OpenShape model\n",
        "    features_tensor = features_tensor.unsqueeze(0)  # Adds a batch dimension, making it [1, N, 6]\n",
        "    features_tensor = features_tensor.transpose(1, 2)  # Transposes to get [1, 6, N], matching the expected [B, C, N] format\n",
        "\n",
        "    # Returning tensors instead of ME-specific batched coordinates\n",
        "    return xyz_tensor, features_tensor\n",
        "\n",
        "def filter_for_OpenShape(pointcloud, num_points=10000, y_up=True):\n",
        "    xyz = np.asarray(pointcloud.points)  # Get xyz coordinates\n",
        "    rgb = np.asarray(pointcloud.colors)  # Get rgb colors\n",
        "    n = xyz.shape[0]\n",
        "\n",
        "    # Sample num_points points if necessary\n",
        "    if n > num_points:\n",
        "        idx = random.sample(range(n), num_points)\n",
        "        xyz = xyz[idx]\n",
        "        #rgb = rgb[idx]\n",
        "    elif n < num_points:\n",
        "        print(f\"Warning: requested {num_points} points, but file has only {n} points.\", file=sys.stderr)\n",
        "\n",
        "    # Adjust orientation by swapping y and z if requested\n",
        "    if y_up:\n",
        "        xyz[:, [1, 2]] = xyz[:, [2, 1]]\n",
        "\n",
        "    # Normalize the point cloud coordinates\n",
        "    xyz_normalized = normalize_pc(xyz)\n",
        "\n",
        "    # Handle cases where rgb might be missing\n",
        "    if rgb.size == 0:\n",
        "        rgb = np.ones_like(xyz_normalized) * 0.4  # Default to a constant color if missing\n",
        "\n",
        "    # Concatenate xyz with rgb\n",
        "    features = np.concatenate([xyz_normalized, rgb], axis=1)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    xyz_tensor = torch.from_numpy(xyz_normalized).float()\n",
        "    features_tensor = torch.from_numpy(features).float()\n",
        "\n",
        "    # Add batch dimention to fit as single input to OpenShape model\n",
        "    features_tensor = features_tensor.unsqueeze(0)  # Adds a batch dimension, making it [1, N, 6]\n",
        "    features_tensor = features_tensor.transpose(1, 2)  # Transposes to get [1, 6, N], matching the expected [B, C, N] format\n",
        "\n",
        "    # Returning tensors instead of ME-specific batched coordinates\n",
        "    return xyz_tensor, features_tensor\n"
      ],
      "metadata": {
        "id": "_LyfD_SHnKEu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test that installation and environment works\n",
        "\n",
        "If a feature vector is printed it should all be A OK!"
      ],
      "metadata": {
        "id": "tWsXrNENL40j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xyz, feat = load_ply(\"/content/OpenShape_code/demo/owl.ply\")\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "model = model.to(device)\n",
        "feat = feat.to(device)\n",
        "\n",
        "output = model.forward(feat)\n",
        "\n",
        "print(output)\n"
      ],
      "metadata": {
        "id": "TqztyB8JnQVn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "315163fa3c974f23b2a54aab7e3037c7",
            "c4f2cb5a7d1b4de2be02d398c613b57b",
            "86077b4dacb7496d8b660b4d42cba49e",
            "5b42532e3ace46e68ada1b1f216db7b6",
            "0601abf594964e2f91fbcd25fe1dc692",
            "a119d9c67a934b208a80bee37063db9a",
            "83645d5001c948e0ba3d1a3fcfe0c10d",
            "985c051a5dc640b2a6ef7fee3417f078",
            "2c1d1a10fecd4ba2884018188c73c8fa",
            "ad2f21d38f11401397e89ac77a729d00",
            "4b6718923d544cf0a263792a865a2e6d"
          ]
        },
        "outputId": "8beb76c8-45a8-494c-9046-2ad9947da227"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "315163fa3c974f23b2a54aab7e3037c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-60.4921, -43.3449, -20.4523,  ..., -34.1933,  48.3220, -14.6552]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone 3DOS repo"
      ],
      "metadata": {
        "id": "_90Y_MbTMe84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone 3D_OS repo from github\n",
        "%cd /content\n",
        "!git clone https://github.com/antoalli/3D_OS.git\n",
        "!cd 3D_OS && chmod +x download_data.sh && ./download_data.sh\n",
        "!pip install h5py protobuf lmdb msgpack-numpy ninja scikit-learn"
      ],
      "metadata": {
        "id": "UaL5_GSiTzpg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c739e7ba-935d-42fa-ebd8-0cae7cefb18c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into '3D_OS'...\n",
            "remote: Enumerating objects: 152, done.\u001b[K\n",
            "remote: Counting objects: 100% (152/152), done.\u001b[K\n",
            "remote: Compressing objects: 100% (104/104), done.\u001b[K\n",
            "remote: Total 152 (delta 51), reused 142 (delta 44), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (152/152), 129.35 KiB | 3.70 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "Downloading data in /content/3D_OS/3D_OS_release_data\n",
            "============Downloading ShapeNetCore resampled in \n",
            "--2024-02-19 16:37:17--  https://www.dropbox.com/s/oa3qbujpugw4d43/sncore_fps_4096.tar?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/oa3qbujpugw4d43/sncore_fps_4096.tar [following]\n",
            "--2024-02-19 16:37:17--  https://www.dropbox.com/s/dl/oa3qbujpugw4d43/sncore_fps_4096.tar\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc230a4e96edf3a6e46d2a2dc912.dl-eu.dropboxusercontent.com/cd/0/get/CNnjq7ynswKSpX23qUb2OvDkJ_vnh4W4YFCYJzYOVA74op-7ilvEM4ib9uGL1RAli3JfSZpGt7QW4xFev2-z3EMCwQOROB15JzgoLtE70ogePB7DoJhkSTYiGaxoRSA6gnv55rhCZiUio6duAisDQBHn/file?dl=1# [following]\n",
            "--2024-02-19 16:37:18--  https://uc230a4e96edf3a6e46d2a2dc912.dl-eu.dropboxusercontent.com/cd/0/get/CNnjq7ynswKSpX23qUb2OvDkJ_vnh4W4YFCYJzYOVA74op-7ilvEM4ib9uGL1RAli3JfSZpGt7QW4xFev2-z3EMCwQOROB15JzgoLtE70ogePB7DoJhkSTYiGaxoRSA6gnv55rhCZiUio6duAisDQBHn/file?dl=1\n",
            "Resolving uc230a4e96edf3a6e46d2a2dc912.dl-eu.dropboxusercontent.com (uc230a4e96edf3a6e46d2a2dc912.dl-eu.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc230a4e96edf3a6e46d2a2dc912.dl-eu.dropboxusercontent.com (uc230a4e96edf3a6e46d2a2dc912.dl-eu.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5037998080 (4.7G) [application/binary]\n",
            "Saving to: ‘/content/3D_OS/3D_OS_release_data/tmp_sncore_fps_4096.tar’\n",
            "\n",
            "/content/3D_OS/3D_O 100%[===================>]   4.69G  27.2MB/s    in 3m 5s   \n",
            "\n",
            "2024-02-19 16:40:24 (26.0 MB/s) - ‘/content/3D_OS/3D_OS_release_data/tmp_sncore_fps_4096.tar’ saved [5037998080/5037998080]\n",
            "\n",
            "============\n",
            "============Downloading ModelNet40 + OOD Splits in \n",
            "--2024-02-19 16:41:07--  https://www.dropbox.com/s/c2x3h59nxprjs21/modelnet40_normal_resampled.tar?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/c2x3h59nxprjs21/modelnet40_normal_resampled.tar [following]\n",
            "--2024-02-19 16:41:08--  https://www.dropbox.com/s/dl/c2x3h59nxprjs21/modelnet40_normal_resampled.tar\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uce49c025e00a7838ac49ba8e4ce.dl-eu.dropboxusercontent.com/cd/0/get/CNmAw0HUYvZG7RBseO9cXXG-DxQ2p0qdsf96XZfQUn1oR3YNg1EmnALIvDGO_Iy4JVMv541rI5Ia5vU8BueYRviCkd1IxqFb9XTcz-k9qo0Yy-tQ-lZFpaSuZAKakhqo6EB6ABtYCD2YyD-saLhAwyuA/file?dl=1# [following]\n",
            "--2024-02-19 16:41:08--  https://uce49c025e00a7838ac49ba8e4ce.dl-eu.dropboxusercontent.com/cd/0/get/CNmAw0HUYvZG7RBseO9cXXG-DxQ2p0qdsf96XZfQUn1oR3YNg1EmnALIvDGO_Iy4JVMv541rI5Ia5vU8BueYRviCkd1IxqFb9XTcz-k9qo0Yy-tQ-lZFpaSuZAKakhqo6EB6ABtYCD2YyD-saLhAwyuA/file?dl=1\n",
            "Resolving uce49c025e00a7838ac49ba8e4ce.dl-eu.dropboxusercontent.com (uce49c025e00a7838ac49ba8e4ce.dl-eu.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uce49c025e00a7838ac49ba8e4ce.dl-eu.dropboxusercontent.com (uce49c025e00a7838ac49ba8e4ce.dl-eu.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7599001600 (7.1G) [application/binary]\n",
            "Saving to: ‘/content/3D_OS/3D_OS_release_data/tmp_modelnet40_normal_resampled.tar’\n",
            "\n",
            "/content/3D_OS/3D_O 100%[===================>]   7.08G  24.9MB/s    in 4m 40s  \n",
            "\n",
            "2024-02-19 16:45:49 (25.9 MB/s) - ‘/content/3D_OS/3D_OS_release_data/tmp_modelnet40_normal_resampled.tar’ saved [7599001600/7599001600]\n",
            "\n",
            "============\n",
            "============Downloading ScanObjectNN in \n",
            "--2024-02-19 16:46:51--  https://www.dropbox.com/s/gu0p3rych1k26b7/ScanObjectNN.tar?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/gu0p3rych1k26b7/ScanObjectNN.tar [following]\n",
            "--2024-02-19 16:46:51--  https://www.dropbox.com/s/dl/gu0p3rych1k26b7/ScanObjectNN.tar\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uca2af628e6e31682c459dfaade3.dl-eu.dropboxusercontent.com/cd/0/get/CNlSW6Af7pntEX1fWzvH1qMeyx30b2lffkgaoN0CRIY9tBgn1n0ZOQtQSfLFe54-ayZLHYgs5JVomhLTPjWbhnO5IQWMf0z5JwEPbB5iLXJ72TRqKCHKSmY53COmE4xcLEVnjQO_MidraIjyaUF_032B/file?dl=1# [following]\n",
            "--2024-02-19 16:46:52--  https://uca2af628e6e31682c459dfaade3.dl-eu.dropboxusercontent.com/cd/0/get/CNlSW6Af7pntEX1fWzvH1qMeyx30b2lffkgaoN0CRIY9tBgn1n0ZOQtQSfLFe54-ayZLHYgs5JVomhLTPjWbhnO5IQWMf0z5JwEPbB5iLXJ72TRqKCHKSmY53COmE4xcLEVnjQO_MidraIjyaUF_032B/file?dl=1\n",
            "Resolving uca2af628e6e31682c459dfaade3.dl-eu.dropboxusercontent.com (uca2af628e6e31682c459dfaade3.dl-eu.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uca2af628e6e31682c459dfaade3.dl-eu.dropboxusercontent.com (uca2af628e6e31682c459dfaade3.dl-eu.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2623662080 (2.4G) [application/binary]\n",
            "Saving to: ‘/content/3D_OS/3D_OS_release_data/tmp_ScanObjectNN.tar’\n",
            "\n",
            "/content/3D_OS/3D_O 100%[===================>]   2.44G  24.9MB/s    in 96s     \n",
            "\n",
            "2024-02-19 16:48:29 (26.1 MB/s) - ‘/content/3D_OS/3D_OS_release_data/tmp_ScanObjectNN.tar’ saved [2623662080/2623662080]\n",
            "\n",
            "============\n",
            "============Downloading ModelNet40 with corruptions in \n",
            "--2024-02-19 16:48:42--  https://www.dropbox.com/s/28u4swbyyn3wflz/ModelNet40_corrupted.tar?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/28u4swbyyn3wflz/ModelNet40_corrupted.tar [following]\n",
            "--2024-02-19 16:48:42--  https://www.dropbox.com/s/dl/28u4swbyyn3wflz/ModelNet40_corrupted.tar\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc8c1b74e111ede769a675804a67.dl-eu.dropboxusercontent.com/cd/0/get/CNnn8o9RYBARF2KgCNXfOrLilWjKdLaWfmaDZfUdb_jYJo0vwL3g4SPbt9nDsquYgT3EPPCQ6AGnMsYuzeq-tOe2KGNkloZoY_dDZZnG1zFoWObBXnx6n8iAIjMLLdNzVouAHnHGiVCMElq51x0mSJ__/file?dl=1# [following]\n",
            "--2024-02-19 16:48:42--  https://uc8c1b74e111ede769a675804a67.dl-eu.dropboxusercontent.com/cd/0/get/CNnn8o9RYBARF2KgCNXfOrLilWjKdLaWfmaDZfUdb_jYJo0vwL3g4SPbt9nDsquYgT3EPPCQ6AGnMsYuzeq-tOe2KGNkloZoY_dDZZnG1zFoWObBXnx6n8iAIjMLLdNzVouAHnHGiVCMElq51x0mSJ__/file?dl=1\n",
            "Resolving uc8c1b74e111ede769a675804a67.dl-eu.dropboxusercontent.com (uc8c1b74e111ede769a675804a67.dl-eu.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc8c1b74e111ede769a675804a67.dl-eu.dropboxusercontent.com (uc8c1b74e111ede769a675804a67.dl-eu.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1107384320 (1.0G) [application/binary]\n",
            "Saving to: ‘/content/3D_OS/3D_OS_release_data/tmp_ModelNet40_corrupted.tar’\n",
            "\n",
            "/content/3D_OS/3D_O 100%[===================>]   1.03G  27.0MB/s    in 41s     \n",
            "\n",
            "2024-02-19 16:49:25 (25.6 MB/s) - ‘/content/3D_OS/3D_OS_release_data/tmp_ModelNet40_corrupted.tar’ saved [1107384320/1107384320]\n",
            "\n",
            "============\n",
            "Finished\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Collecting lmdb\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msgpack-numpy\n",
            "  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from msgpack-numpy) (1.0.7)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Installing collected packages: ninja, lmdb, msgpack-numpy\n",
            "Successfully installed lmdb-1.4.1 msgpack-numpy-0.4.8 ninja-1.11.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for displaying point cloud"
      ],
      "metadata": {
        "id": "ktomz4FSAei3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_pointcloud(pointcloud):\n",
        "    points = pointcloud.points\n",
        "\n",
        "    fig = go.Figure(\n",
        "      data=[\n",
        "          go.Scatter3d(\n",
        "            x=np.asarray(points)[:,0],\n",
        "            y=np.asarray(points)[:,1],\n",
        "            z=np.asarray(points)[:,2],\n",
        "            mode='markers',\n",
        "          )\n",
        "      ],\n",
        "      layout=dict(\n",
        "            scene=dict(\n",
        "            xaxis=dict(visible=False),\n",
        "            yaxis=dict(visible=False),\n",
        "            zaxis=dict(visible=False)\n",
        "        )\n",
        "      )\n",
        "    )\n",
        "    fig.show()\n",
        "    time.sleep(1)"
      ],
      "metadata": {
        "id": "SSEL5SEVAdZA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create data for chair\n",
        "\n",
        "We use a 3D chair downloaded from:\n",
        "\n",
        "https://free3d.com/3d-model/office-chair-871087.html\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "seoQcJoGmBkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bpy"
      ],
      "metadata": {
        "id": "o52eGIp-mJ2k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2abf244e-4681-4b26-cbaf-7d9926832b63"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bpy\n",
            "  Downloading bpy-4.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (390.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.1/390.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from bpy) (3.0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bpy) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bpy) (2.31.0)\n",
            "Collecting zstandard (from bpy)\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bpy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bpy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bpy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bpy) (2024.2.2)\n",
            "Installing collected packages: zstandard, bpy\n",
            "Successfully installed bpy-4.0.0 zstandard-0.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def obj_to_pointcloud(obj_file_path, num_samples=10000):\n",
        "    vertices = []\n",
        "    with open(obj_file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            if line.startswith('v '):\n",
        "                parts = line.strip().split()\n",
        "                vertices.append([float(parts[1]), float(parts[2]), float(parts[3])])\n",
        "\n",
        "    vertices_array = np.array(vertices)\n",
        "\n",
        "    if vertices_array.shape[0] < num_samples:\n",
        "        raise ValueError(f\"Not enough vertices to sample: {vertices_array.shape[0]} available, {num_samples} requested.\")\n",
        "\n",
        "    sampled_indices = np.random.choice(vertices_array.shape[0], size=num_samples, replace=False)\n",
        "    sampled_vertices = vertices_array[sampled_indices]\n",
        "\n",
        "    return sampled_vertices\n",
        "\n",
        "obj_file_path = '/content/Office chair.obj'\n",
        "\n",
        "try:\n",
        "    point_cloud = obj_to_pointcloud(obj_file_path)\n",
        "    output_file_path = 'output_point_cloud.npy'\n",
        "    np.save(output_file_path, point_cloud)\n",
        "    print(f\"Sampled point cloud saved to {output_file_path}\")\n",
        "except ValueError as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlLMJBaQuLeM",
        "outputId": "956a4742-19cc-45ee-e3dd-2c9c9518f306"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled point cloud saved to output_point_cloud.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create dataset of correctly produced chairs\n",
        "To get realistic measurements we add gaussian noise to the point cloud to simulate measurement noise."
      ],
      "metadata": {
        "id": "ApGQMjIqxGPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import open3d as o3d\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "class PointCloudDatasetWithLabels(Dataset):\n",
        "    def __init__(self, point_clouds, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            point_clouds (list): List of point clouds, each point cloud is a numpy array or PyTorch tensor.\n",
        "            labels (list): List of labels corresponding to each point cloud.\n",
        "        \"\"\"\n",
        "        assert len(point_clouds) == len(labels), \"Point clouds and labels must have the same length\"\n",
        "        self.point_clouds = [torch.tensor(pc, dtype=torch.float) if not torch.is_tensor(pc) else pc for pc in point_clouds]\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.point_clouds)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.point_clouds[idx], self.labels[idx]\n",
        "\n",
        "def add_gaussian_noise_to_pointcloud(pcd, mean=0, std_dev=0.01):\n",
        "    points = np.asarray(pcd.points)\n",
        "\n",
        "    noise = np.random.normal(mean, std_dev, points.shape)\n",
        "\n",
        "    noisy_points = points + noise\n",
        "\n",
        "    noisy_pcd = o3d.geometry.PointCloud()\n",
        "    noisy_pcd.points = o3d.utility.Vector3dVector(noisy_points)\n",
        "\n",
        "    return noisy_pcd\n",
        "\n",
        "def generate_noisy_chairs(pointcloud, number_of_noisy_chairs=100):\n",
        "    noisy_chairs = []\n",
        "    for i in range(0, number_of_noisy_chairs):\n",
        "        noisy_pcd = add_gaussian_noise_to_pointcloud(pointcloud)\n",
        "        noisy_chairs.append(noisy_pcd)\n",
        "    return noisy_chairs\n",
        "\n",
        "\n",
        "points = np.load(\"/content/output_point_cloud.npy\")\n",
        "points = torch.from_numpy(points)\n",
        "print(points.shape)\n",
        "points = points.reshape(-1, 3)\n",
        "print(points.shape)\n",
        "\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(points)\n",
        "\n",
        "noisy_chairs = generate_noisy_chairs(pcd, number_of_noisy_chairs=600)\n",
        "noisy_chairs_labels = []\n",
        "for i in range(0, len(noisy_chairs)):\n",
        "    _, noisy_chairs[i] = filter_for_OpenShape(noisy_chairs[i], num_points=10000)\n",
        "    noisy_chairs_labels.append(1)\n",
        "\n",
        "# Assuming `point_cloud_list` is your list of point cloud inputs\n",
        "noisy_correct_chairs_dataset = PointCloudDatasetWithLabels(noisy_chairs, noisy_chairs_labels)\n",
        "\n",
        "# Create a DataLoader\n",
        "noisy_correct_chairs_dataloader = DataLoader(noisy_correct_chairs_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "total_size = len(noisy_correct_chairs_dataset)\n",
        "train_size = int(total_size * 0.5)  # 80% of the total size\n",
        "test_size = total_size - train_size  # The rest for testing/validation\n",
        "\n",
        "# Perform the split\n",
        "train_dataset, id_dataset = random_split(noisy_correct_chairs_dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "id_loader = DataLoader(id_dataset, batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HqxGLHfoFGh",
        "outputId": "0555df95-d895-46ce-98bd-ef9805c7634f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10000, 3])\n",
            "torch.Size([10000, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create dataset of defect chairs"
      ],
      "metadata": {
        "id": "T9hTd58X8iqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import open3d as o3d\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "# Localized Distortion\n",
        "def distort_chair(chair_points):\n",
        "    max_values = np.amax(chair_points, axis=0)\n",
        "    x_max, y_max, z_max = max_values[0], max_values[1], max_values[2]\n",
        "\n",
        "    min_values = np.amin(chair_points, axis=0)\n",
        "    x_min, y_min, z_min = min_values[0], min_values[1], min_values[2]\n",
        "\n",
        "    min_bound = np.array([x_min, y_min, z_min])\n",
        "    max_bound = np.array([x_max, y_max, z_max])\n",
        "    region_indices = np.all((chair_points >= min_bound) & (chair_points <= max_bound), axis=1)\n",
        "    chair_points[region_indices] += np.random.normal(0, 0.5, chair_points[region_indices].shape)\n",
        "    return chair_points\n",
        "\n",
        "# Missing parts\n",
        "def remove_points_from_chair(chair_points):\n",
        "    num_missing_points = 100\n",
        "    missing_indices = np.random.choice(len(chair_points), num_missing_points, replace=False)\n",
        "    chair_points = np.delete(chair_points, missing_indices, axis=0)\n",
        "    return chair_points\n",
        "\n",
        "def remove_points_within_radius(point_cloud, radius):\n",
        "    random_index = np.random.randint(len(point_cloud))\n",
        "    random_point = point_cloud[random_index]\n",
        "\n",
        "    squared_distances = np.sum((point_cloud - random_point) ** 2, axis=1)\n",
        "    squared_radius = radius ** 2\n",
        "\n",
        "    mask = squared_distances > squared_radius\n",
        "\n",
        "    return point_cloud[mask]\n",
        "\n",
        "def add_random_points(chair_points, final_size=10000):\n",
        "    size = len(chair_points)\n",
        "    points_to_add = final_size - size\n",
        "\n",
        "    noise_indices = np.random.choice(len(chair_points), points_to_add, replace=False)\n",
        "    new_points = chair_points[noise_indices] + np.random.normal(0, 0.1, chair_points[noise_indices].shape)\n",
        "\n",
        "    return np.concatenate((chair_points, new_points), axis=0)\n",
        "\n",
        "# Scale some parts\n",
        "def scale_chair(chair_points, scale):\n",
        "    scale_factor = scale\n",
        "    chair_points *= scale_factor\n",
        "    return chair_points\n",
        "\n",
        "def add_noise_to_chair(chair_points, std = 10):\n",
        "    noise_indices = np.random.choice(len(chair_points), 10, replace=False)\n",
        "    chair_points[noise_indices] += np.random.normal(0, std, chair_points[noise_indices].shape)\n",
        "    return chair_points\n",
        "\n",
        "# Make chair asymmertric\n",
        "def make_chair_asymmetric(chair_points):\n",
        "    asymmetry_indices = chair_points[:, 0] > np.mean(chair_points[:, 0])  # For example, right half\n",
        "    chair_points[asymmetry_indices] *= np.array([1.0, 0.9, 0.9])  # Scale down y and z\n",
        "    return chair_points\n",
        "\n",
        "\n",
        "def apply_asymmetrical_scaling(point_cloud, scale_factors=np.array([1.0, 0.9, 0.9])):\n",
        "    axis = np.random.choice([0, 1, 2])\n",
        "\n",
        "    median_value = np.median(point_cloud[:, axis])\n",
        "\n",
        "    if np.random.rand() > 0.5:\n",
        "        selected_half_mask = point_cloud[:, axis] > median_value\n",
        "    else:\n",
        "        selected_half_mask = point_cloud[:, axis] <= median_value\n",
        "\n",
        "    point_cloud[selected_half_mask] *= np.array(scale_factors)\n",
        "\n",
        "    return point_cloud\n",
        "\n",
        "\n",
        "def random_rotation_matrix():\n",
        "    \"\"\"Generate a random rotation matrix.\"\"\"\n",
        "    theta = np.random.uniform(0, 2 * np.pi)\n",
        "\n",
        "    axis = np.random.randn(3)\n",
        "    axis = axis / np.linalg.norm(axis)\n",
        "\n",
        "    K = np.array([[0, -axis[2], axis[1]],\n",
        "                  [axis[2], 0, -axis[0]],\n",
        "                  [-axis[1], axis[0], 0]])\n",
        "    rotation_matrix = np.eye(3) + np.sin(theta) * K + (1 - np.cos(theta)) * np.dot(K, K)\n",
        "\n",
        "    return rotation_matrix\n",
        "\n",
        "def create_random_defect(pcd, type_of_defect):\n",
        "    chair_points = np.asarray(pcd.points)\n",
        "\n",
        "    if type_of_defect == \"distort\":\n",
        "        chair_points = distort_chair(chair_points)\n",
        "    elif type_of_defect == \"remove parts\":\n",
        "        chair_points = remove_points_within_radius(chair_points, 300)\n",
        "        chair_points = add_random_points(chair_points)\n",
        "    elif type_of_defect == \"scale\":\n",
        "        chair_points = scale_chair(chair_points, scale=random.uniform(0.8, 1.3))\n",
        "    elif type_of_defect == \"add noise\":\n",
        "        chair_points = add_noise_to_chair(chair_points)\n",
        "    elif type_of_defect == \"asymmetrical\":\n",
        "        rotation_matrix = random_rotation_matrix()\n",
        "        rotation_matrix_inv = rotation_matrix.T\n",
        "        chair_points = np.dot(chair_points, rotation_matrix.T)\n",
        "        chair_points = apply_asymmetrical_scaling(chair_points, scale_factors=np.array([1.0, 0.8, 0.8]))\n",
        "        chair_points = np.dot(chair_points, rotation_matrix_inv.T)\n",
        "\n",
        "    defect_pcd = o3d.geometry.PointCloud()\n",
        "    defect_pcd.points = o3d.utility.Vector3dVector(chair_points)\n",
        "    return defect_pcd\n",
        "\n",
        "def generate_defect_chairs(pointcloud, type_of_defects, number_of_noisy_chairs=100):\n",
        "    defect_chairs = []\n",
        "    num_each_type = number_of_noisy_chairs //len(type_of_defects)\n",
        "    for defect in type_of_defects:\n",
        "        for i in range(0, num_each_type):\n",
        "            # Add defect\n",
        "            defect_pcd = create_random_defect(pcd, defect)\n",
        "            # Add measurement noise\n",
        "            defect_pcd = add_gaussian_noise_to_pointcloud(defect_pcd, mean=0, std_dev=0.01)\n",
        "            defect_chairs.append(defect_pcd)\n",
        "    return defect_chairs\n",
        "\n",
        "type_of_defects = [\"distort\", \"remove parts\", \"scale\", \"add noise\", \"asymmetrical\"]\n",
        "defect_chairs = generate_defect_chairs(pcd, type_of_defects, number_of_noisy_chairs=500)\n",
        "defect_chairs_labels = np.zeros(len(defect_chairs))\n",
        "for i in range(0, len(defect_chairs)):\n",
        "    _, defect_chairs[i] = filter_for_OpenShape(defect_chairs[i], num_points=10000)\n",
        "\n",
        "# Assuming `point_cloud_list` is your list of point cloud inputs\n",
        "noisy_defect_chairs_dataset = PointCloudDatasetWithLabels(defect_chairs, defect_chairs_labels)\n",
        "\n",
        "# Create a DataLoader\n",
        "ood_loader = DataLoader(noisy_defect_chairs_dataset, batch_size=1, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "0-QjNG6U8n-Z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the DataLoader\n",
        "for data in train_loader:\n",
        "    print(\"train_loader\")\n",
        "    if isinstance(data, tuple) or isinstance(data, list):\n",
        "        inputs, targets = data\n",
        "        print(f\"Input batch dimensions: {inputs.shape}\")\n",
        "        print(f\"Target batch dimensions: {targets.shape}\")\n",
        "    else:\n",
        "        # If there are no targets/labels\n",
        "        print(f\"Input batch dimensions: {data.shape}\")\n",
        "    break  # Break after the first batch to just check the dimensions\n",
        "\n",
        "# Iterate through the DataLoader\n",
        "for data in id_loader:\n",
        "    print(\"id_loader\")\n",
        "    if isinstance(data, tuple) or isinstance(data, list):\n",
        "        inputs, targets = data\n",
        "        print(f\"Input batch dimensions: {inputs.shape}\")\n",
        "        print(f\"Target batch dimensions: {targets.shape}\")\n",
        "    else:\n",
        "        # If there are no targets/labels\n",
        "        print(f\"Input batch dimensions: {data.shape}\")\n",
        "    break  # Break after the first batch to just check the dimensions\n",
        "\n",
        "# Iterate through the DataLoader\n",
        "for data in ood_loader:\n",
        "    print(\"ood_loader\")\n",
        "    if isinstance(data, tuple) or isinstance(data, list):\n",
        "        inputs, targets = data\n",
        "        print(f\"Input batch dimensions: {inputs.shape}\")\n",
        "        print(f\"Target batch dimensions: {targets.shape}\")\n",
        "    else:\n",
        "        # If there are no targets/labels\n",
        "        print(f\"Input batch dimensions: {data.shape}\")\n",
        "    break  # Break after the first batch to just check the dimensions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzmaKFSTh13Y",
        "outputId": "90d4b4f1-efef-41c2-8c2b-caf9cea70f7e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loader\n",
            "Input batch dimensions: torch.Size([1, 1, 6, 10000])\n",
            "Target batch dimensions: torch.Size([1])\n",
            "id_loader\n",
            "Input batch dimensions: torch.Size([1, 1, 6, 10000])\n",
            "Target batch dimensions: torch.Size([1])\n",
            "ood_loader\n",
            "Input batch dimensions: torch.Size([1, 1, 6, 10000])\n",
            "Target batch dimensions: torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nBNqsX-cZhXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing PointNet for the chair defect detection"
      ],
      "metadata": {
        "id": "mpBwf3quAO8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title JS Shell\n",
        "%%html\n",
        "<div id=term_demo></div>\n",
        "<script src=\"https://code.jquery.com/jquery-latest.js\"></script>\n",
        "<script src=\"https://cdn.jsdelivr.net/npm/jquery.terminal/js/jquery.terminal.min.js\"></script>\n",
        "<link href=\"https://cdn.jsdelivr.net/npm/jquery.terminal/css/jquery.terminal.min.css\" rel=\"stylesheet\"/>\n",
        "<script>\n",
        "  $('#term_demo').terminal(function(command) {\n",
        "      if (command !== '') {\n",
        "          try {\n",
        "              var result = window.eval(command);\n",
        "              if (result !== undefined) {\n",
        "                  this.echo(new String(result));\n",
        "              }\n",
        "          } catch(e) {\n",
        "              this.error(new String(e));\n",
        "          }\n",
        "      } else {\n",
        "          this.echo('');\n",
        "      }\n",
        "  }, {\n",
        "      greetings: 'Welcome to JavaScript Shell',\n",
        "      name: 'js_demo',\n",
        "      height: 200,\n",
        "      prompt: 'js> '\n",
        "  });\n",
        "\n",
        "from IPython.display import JSON\n",
        "from google.colab import output\n",
        "from subprocess import getoutput\n",
        "import os\n",
        "\n",
        "def shell(command):\n",
        "  if command.startswith('cd'):\n",
        "    path = command.strip().split(maxsplit=1)[1]\n",
        "    os.chdir(path)\n",
        "    return JSON([''])\n",
        "  return JSON([getoutput(command)])\n",
        "output.register_callback('shell', shell)\n",
        "\n",
        "#@title Colab Shell\n",
        "%%html\n",
        "<div id=term_demo></div>\n",
        "<script src=\"https://code.jquery.com/jquery-latest.js\"></script>\n",
        "<script src=\"https://cdn.jsdelivr.net/npm/jquery.terminal/js/jquery.terminal.min.js\"></script>\n",
        "<link href=\"https://cdn.jsdelivr.net/npm/jquery.terminal/css/jquery.terminal.min.css\" rel=\"stylesheet\"/>\n",
        "<script>\n",
        "  $('#term_demo').terminal(async function(command) {\n",
        "      if (command !== '') {\n",
        "          try {\n",
        "              let res = await google.colab.kernel.invokeFunction('shell', [command])\n",
        "              let out = res.data['application/json'][0]\n",
        "              this.echo(new String(out))\n",
        "          } catch(e) {\n",
        "              this.error(new String(e));\n",
        "          }\n",
        "      } else {\n",
        "          this.echo('');\n",
        "      }\n",
        "  }, {\n",
        "      greetings: 'Welcome to Colab Shell',\n",
        "      name: 'colab_demo',\n",
        "      height: 250,\n",
        "      prompt: 'colab > '\n",
        "  });"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "TdQ85WJQAOT8",
        "outputId": "46a32801-fc63-49a9-a9a5-ae9f3d5cc72c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div id=term_demo></div>\n",
              "<script src=\"https://code.jquery.com/jquery-latest.js\"></script>\n",
              "<script src=\"https://cdn.jsdelivr.net/npm/jquery.terminal/js/jquery.terminal.min.js\"></script>\n",
              "<link href=\"https://cdn.jsdelivr.net/npm/jquery.terminal/css/jquery.terminal.min.css\" rel=\"stylesheet\"/>\n",
              "<script>\n",
              "  $('#term_demo').terminal(function(command) {\n",
              "      if (command !== '') {\n",
              "          try {\n",
              "              var result = window.eval(command);\n",
              "              if (result !== undefined) {\n",
              "                  this.echo(new String(result));\n",
              "              }\n",
              "          } catch(e) {\n",
              "              this.error(new String(e));\n",
              "          }\n",
              "      } else {\n",
              "          this.echo('');\n",
              "      }\n",
              "  }, {\n",
              "      greetings: 'Welcome to JavaScript Shell',\n",
              "      name: 'js_demo',\n",
              "      height: 200,\n",
              "      prompt: 'js> '\n",
              "  });\n",
              "\n",
              "from IPython.display import JSON\n",
              "from google.colab import output\n",
              "from subprocess import getoutput\n",
              "import os\n",
              "\n",
              "def shell(command):\n",
              "  if command.startswith('cd'):\n",
              "    path = command.strip().split(maxsplit=1)[1]\n",
              "    os.chdir(path)\n",
              "    return JSON([''])\n",
              "  return JSON([getoutput(command)])\n",
              "output.register_callback('shell', shell)\n",
              "\n",
              "#@title Colab Shell\n",
              "%%html\n",
              "<div id=term_demo></div>\n",
              "<script src=\"https://code.jquery.com/jquery-latest.js\"></script>\n",
              "<script src=\"https://cdn.jsdelivr.net/npm/jquery.terminal/js/jquery.terminal.min.js\"></script>\n",
              "<link href=\"https://cdn.jsdelivr.net/npm/jquery.terminal/css/jquery.terminal.min.css\" rel=\"stylesheet\"/>\n",
              "<script>\n",
              "  $('#term_demo').terminal(async function(command) {\n",
              "      if (command !== '') {\n",
              "          try {\n",
              "              let res = await google.colab.kernel.invokeFunction('shell', [command])\n",
              "              let out = res.data['application/json'][0]\n",
              "              this.echo(new String(out))\n",
              "          } catch(e) {\n",
              "              this.error(new String(e));\n",
              "          }\n",
              "      } else {\n",
              "          this.echo('');\n",
              "      }\n",
              "  }, {\n",
              "      greetings: 'Welcome to Colab Shell',\n",
              "      name: 'colab_demo',\n",
              "      height: 250,\n",
              "      prompt: 'colab > '\n",
              "  });\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a PointNet model\n",
        "Code from repo: https://github.com/fxia22/pointnet.pytorch.git\n",
        "\n",
        "From paper:\n",
        "Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. Pointnet: Deep learning on point\n",
        "sets for 3d classification and segmentation. In Proceedings of the IEEE conference on computer\n",
        "vision and pattern recognition, pages 652–660, 2017."
      ],
      "metadata": {
        "id": "hOC-SblCHA9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fxia22/pointnet.pytorch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rh3I2DjvUMLW",
        "outputId": "88e0a4e0-164f-425d-fa87-9f1d1a0adc16"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pointnet.pytorch'...\n",
            "remote: Enumerating objects: 213, done.\u001b[K\n",
            "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 213 (delta 0), reused 2 (delta 0), pack-reused 211\u001b[K\n",
            "Receiving objects: 100% (213/213), 229.91 KiB | 5.11 MiB/s, done.\n",
            "Resolving deltas: 100% (125/125), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create dataset"
      ],
      "metadata": {
        "id": "Q7736Kf1pZod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import open3d as o3d\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "class PointCloudDatasetWithLabels(Dataset):\n",
        "    def __init__(self, point_clouds, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            point_clouds (list): List of point clouds, each point cloud is a numpy array or PyTorch tensor.\n",
        "            labels (list): List of labels corresponding to each point cloud.\n",
        "        \"\"\"\n",
        "        assert len(point_clouds) == len(labels), \"Point clouds and labels must have the same length\"\n",
        "        self.point_clouds = [torch.tensor(pc, dtype=torch.float) if not torch.is_tensor(pc) else pc for pc in point_clouds]\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.point_clouds)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.point_clouds[idx], self.labels[idx]\n",
        "\n",
        "def add_gaussian_noise_to_pointcloud(pcd, mean=0, std_dev=0.01):\n",
        "    points = np.asarray(pcd.points)\n",
        "\n",
        "    noise = np.random.normal(mean, std_dev, points.shape)\n",
        "\n",
        "    noisy_points = points + noise\n",
        "\n",
        "    noisy_pcd = o3d.geometry.PointCloud()\n",
        "    noisy_pcd.points = o3d.utility.Vector3dVector(noisy_points)\n",
        "\n",
        "    return noisy_pcd\n",
        "\n",
        "def generate_noisy_chairs(pointcloud, number_of_noisy_chairs=100):\n",
        "    noisy_chairs = []\n",
        "    for i in range(0, number_of_noisy_chairs):\n",
        "        noisy_pcd = add_gaussian_noise_to_pointcloud(pointcloud)\n",
        "        noisy_chairs.append(noisy_pcd)\n",
        "    return noisy_chairs\n",
        "\n",
        "\n",
        "points = np.load(\"/content/output_point_cloud.npy\")\n",
        "points = torch.from_numpy(points)\n",
        "print(points.shape)\n",
        "points = points.reshape(-1, 3)\n",
        "print(points.shape)\n",
        "\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(points)\n",
        "\n",
        "noisy_chairs = generate_noisy_chairs(pcd, number_of_noisy_chairs=600)\n",
        "noisy_chairs_labels = []\n",
        "for i in range(0, len(noisy_chairs)):\n",
        "    _, noisy_chairs[i] = filter_for_OpenShape(noisy_chairs[i], num_points=10000)\n",
        "    noisy_chairs_labels.append(6)\n",
        "\n",
        "# Assuming `point_cloud_list` is your list of point cloud inputs\n",
        "noisy_correct_chairs_dataset = PointCloudDatasetWithLabels(noisy_chairs, noisy_chairs_labels)\n",
        "\n",
        "# Create a DataLoader\n",
        "noisy_correct_chairs_dataloader = DataLoader(noisy_correct_chairs_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "total_size = len(noisy_correct_chairs_dataset)\n",
        "train_size = int(total_size * 0.5)  # 80% of the total size\n",
        "test_size = total_size - train_size  # The rest for testing/validation\n",
        "\n",
        "# Perform the split\n",
        "train_dataset, id_dataset = random_split(noisy_correct_chairs_dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "id_loader = DataLoader(id_dataset, batch_size=1, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "CF_2Nmm0arXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9c2e415-8a09-48f2-829d-5ba1df0bff9f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10000, 3])\n",
            "torch.Size([10000, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py protobuf lmdb msgpack-numpy ninja scikit-learn"
      ],
      "metadata": {
        "id": "riuBtkJVqXby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac3b7ff-5737-45d1-8d0a-806c03b96c8e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: msgpack-numpy in /usr/local/lib/python3.10/dist-packages (0.4.8)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (1.11.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from msgpack-numpy) (1.0.7)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub wandb omegaconf torch_redstone einops tqdm open3d dgl timm\n",
        "!pip install --upgrade https://github.com/unlimblue/KNN_CUDA/releases/download/0.2/KNN_CUDA-0.2-py3-none-any.whl"
      ],
      "metadata": {
        "id": "iHL-F8Z_rY0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d8903f-0ffa-4ab6-e252-d0a5009c394f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.3)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: torch_redstone in /usr/local/lib/python3.10/dist-packages (0.0.5)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: open3d in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.10/dist-packages (1.1.3)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.42)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.40.5)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_redstone) (1.25.2)\n",
            "Requirement already satisfied: dash>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (2.15.0)\n",
            "Requirement already satisfied: werkzeug>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.0.1)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (5.9.2)\n",
            "Requirement already satisfied: configargparse in /usr/local/lib/python3.10/dist-packages (from open3d) (1.7)\n",
            "Requirement already satisfied: ipywidgets>=8.0.4 in /usr/local/lib/python3.10/dist-packages (from open3d) (8.1.2)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from open3d) (2.4.0)\n",
            "Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (9.4.0)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.2.2)\n",
            "Requirement already satisfied: pyquaternion in /usr/local/lib/python3.10/dist-packages (from open3d) (0.9.9)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu121)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.2)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.2.5)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.15.0)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.0.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (7.0.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (0.2.1)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.10 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (4.0.10)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (3.2.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=2.2.3->open3d) (2.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (2.1.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.17.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.2.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.17.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat>=5.7.0->open3d) (4.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
            "Collecting KNN-CUDA==0.2\n",
            "  Downloading https://github.com/unlimblue/KNN_CUDA/releases/download/0.2/KNN_CUDA-0.2-py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from KNN-CUDA==0.2) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from KNN-CUDA==0.2) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from KNN-CUDA==0.2) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->KNN-CUDA==0.2) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->KNN-CUDA==0.2) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->KNN-CUDA==0.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->KNN-CUDA==0.2) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->KNN-CUDA==0.2) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->KNN-CUDA==0.2) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->KNN-CUDA==0.2) (2.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->KNN-CUDA==0.2) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->KNN-CUDA==0.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->KNN-CUDA==0.2) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->KNN-CUDA==0.2) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->KNN-CUDA==0.2) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change folder to 3D_OS to get the same dataloaders\n",
        "%cd \"/content/3D_OS\"\n",
        "!ls utils\n",
        "\n",
        "import os\n",
        "\n",
        "# Change this path to the root directory of the cloned repository\n",
        "repo_root = '/content/3D_OS'\n",
        "\n",
        "os.chdir(repo_root)\n",
        "print(\"Current Working Directory:\", os.getcwd())\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "\n",
        "sys.path.append(os.getcwd())\n",
        "import os.path as osp\n",
        "import time\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from utils.utils import *\n",
        "from utils.dist import *\n",
        "# noinspection PyUnresolvedReferences\n",
        "from utils.data_utils import H5_Dataset\n",
        "#from datasets.modelnet import *\n",
        "from datasets.scanobject import *\n",
        "from models.classifiers import Classifier\n",
        "from utils.ood_utils import get_confidence, eval_ood_sncore, iterate_data_odin, \\\n",
        "    iterate_data_energy, iterate_data_gradnorm, iterate_data_react, estimate_react_thres, print_ood_output, \\\n",
        "    get_penultimate_feats, get_network_output\n",
        "import wandb\n",
        "from base_args import add_base_args\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from models.common import convert_model_state, logits_entropy_loss\n",
        "from models.ARPL_utils import Generator, Discriminator\n",
        "from classifiers.common import train_epoch_cla, train_epoch_rsmix_exposure, train_epoch_cs\n",
        "from classifiers.trainer_ddp_cla_md import get_args, load_yaml, get_md_eval_loaders\n",
        "\n",
        "# Code from 3DOS repo classifiers/trainer_ddp_cla_md.py line 192-478\n",
        "\n",
        "#  python -m torch.distributed.launch --nproc_per_node=1 Failure_Analysis/custom\\\n",
        "# tests/evaluating_PointNet_cosine_MLS.py --config cfgs/pn2-msg.yaml\n",
        "# --exp_name PN2_cosine_SR1 --src SR1 --loss cosine -mode eval\n",
        "# --ckpt_path outputs/PN2_cosine_SR1/models/model_best.pth\n",
        "\n",
        "\n",
        "# Code from 3DOS repo classifiers/trainer_ddp_cla_md.py line 468-478\n",
        "def eval_ood_md2sonn(opt, config):\n",
        "    print(f\"Arguments: {opt}\")\n",
        "    set_random_seed(opt.seed)\n",
        "\n",
        "    dataloader_config = {\n",
        "        'batch_size': opt.batch_size, 'drop_last': False, 'shuffle': False,\n",
        "        'num_workers': opt.num_workers, 'sampler': None, 'worker_init_fn': init_np_seed}\n",
        "\n",
        "    # whole evaluation is done on ScanObject RW data\n",
        "    sonn_args = {\n",
        "        'data_root': opt.data_root,\n",
        "        'sonn_split': opt.sonn_split,\n",
        "        'h5_file': opt.sonn_h5_name,\n",
        "        'split': 'all',  # we use both training (unused) and test samples during evaluation\n",
        "        'num_points': opt.num_points_test,  # default: use all 2048 sonn points to avoid sampling randomicity\n",
        "        'transforms': None  # no augmentation applied at inference time\n",
        "    }\n",
        "\n",
        "    train_loader, _ = get_md_eval_loaders(opt)\n",
        "    if opt.src == 'SR1':\n",
        "        print(\"Src is SR1\\n\")\n",
        "        id_loader = DataLoader(ScanObject(class_choice=\"sonn_2_mdSet1\", **sonn_args), **dataloader_config)\n",
        "        ood1_loader = DataLoader(ScanObject(class_choice=\"sonn_2_mdSet2\", **sonn_args), **dataloader_config)\n",
        "    elif opt.src == 'SR2':\n",
        "        print(\"Src is SR2\\n\")\n",
        "        id_loader = DataLoader(ScanObject(class_choice=\"sonn_2_mdSet2\", **sonn_args), **dataloader_config)\n",
        "        ood1_loader = DataLoader(ScanObject(class_choice=\"sonn_2_mdSet1\", **sonn_args), **dataloader_config)\n",
        "    else:\n",
        "        raise ValueError(f\"OOD evaluation - wrong src: {opt.src}\")\n",
        "\n",
        "    ood2_loader = DataLoader(ScanObject(class_choice=\"sonn_ood_common\", **sonn_args), **dataloader_config)\n",
        "\n",
        "    return train_loader, id_loader, ood1_loader, ood2_loader\n",
        "\n",
        "class Options:\n",
        "    def __init__(self, dictionary):\n",
        "        for key, value in dictionary.items():\n",
        "            setattr(self, key, value)\n",
        "\n",
        "opt_dict = {\n",
        "    \"apply_fix_cellphone\": True,\n",
        "    \"augm_set\": 'rw',\n",
        "    \"batch_size\": 1,\n",
        "    \"checkpoints_dir\": 'outputs',\n",
        "    \"ckpt_path\": 'outputs/PN2_cosine_SR1/models/model_best.pth',\n",
        "    \"config\": 'cfgs/pn2-msg.yaml',\n",
        "    \"corruption\": None,\n",
        "    \"cs\": False,\n",
        "    \"cs_beta\": 0.1,\n",
        "    \"cs_gan_lr\": 0.0002,\n",
        "    \"data_root\": \"/content/3D_OS/3D_OS_release_data\",\n",
        "    \"epochs\": 250,\n",
        "    \"eval_step\": 1,\n",
        "    \"exp_name\": 'PN2_cosine_SR1',\n",
        "    \"grad_norm_clip\": -1,\n",
        "    \"local_rank\": 0,\n",
        "    \"loss\": 'cosine',\n",
        "    \"num_points\": 10000,\n",
        "    \"num_points_test\": 10000,\n",
        "    \"num_workers\": 6,\n",
        "    \"resume\": None,\n",
        "    \"save_feats\": None,\n",
        "    \"save_step\": 10,\n",
        "    \"script_mode\": 'eval',\n",
        "    \"seed\": 1,\n",
        "    \"sonn_h5_name\": 'objectdataset.h5',\n",
        "    \"sonn_split\": 'main_split',\n",
        "    \"src\": 'SR1',\n",
        "    \"tar1\": 'none',\n",
        "    \"tar2\": 'none',\n",
        "    \"use_amp\": False,\n",
        "    \"use_sync_bn\": False,\n",
        "    \"wandb_group\": 'md-2-sonn-augmCorr',\n",
        "    \"wandb_name\": None,\n",
        "    \"wandb_proj\": 'benchmark-3d-ood-cla'\n",
        "}\n",
        "\n",
        "opt = Options(opt_dict)\n",
        "\n",
        "config = {'optimizer': {'type': 'adam',\n",
        "                        'skip_wd': [],\n",
        "                        'weight_decay': 0.0001,\n",
        "                        'kwargs': {'lr': 0.001}\n",
        "                        },\n",
        "          'scheduler': {'type': 'CosLR',\n",
        "                        'kwargs': {'t_initial': 250,\n",
        "                                   'cycle_limit': 1,\n",
        "                                   'lr_min': 1e-05\n",
        "                                   }\n",
        "                        },\n",
        "          'model': {'ENCO_NAME': 'pn2-msg',\n",
        "                    'dropout': 0.5,\n",
        "                    'cla_input_dim': 1024,\n",
        "                    'act': 'relu'\n",
        "                    }\n",
        "          }\n",
        "\n",
        "print(opt)\n",
        "print(config)\n",
        "\n",
        "train_loader_SR, src_loader_SR, tar1_loader_SR, tar2_loader_SR = eval_ood_md2sonn(opt, config)\n",
        "\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "WzsElplniq4W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f200663f-ba28-445b-9776-967057ce04f4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/3D_OS\n",
            "data_utils.py  dist.py\t__init__.py  ood_metrics.py  ood_utils.py  rsmix_provider.py  utils.py\n",
            "Current Working Directory: /content/3D_OS\n",
            "Cannot import torchlars\n",
            "Cannot load RSCNN: No module named 'pointnet2_ops'\n",
            "Cannot load PCT: No module named 'pointnet2_ops'\n",
            "Cannot load PointMLP: No module named 'pointnet2_ops'\n",
            "Cannot load PointNet2: No module named 'pointnet2_ops'\n",
            "<__main__.Options object at 0x7861ba528430>\n",
            "{'optimizer': {'type': 'adam', 'skip_wd': [], 'weight_decay': 0.0001, 'kwargs': {'lr': 0.001}}, 'scheduler': {'type': 'CosLR', 'kwargs': {'t_initial': 250, 'cycle_limit': 1, 'lr_min': 1e-05}}, 'model': {'ENCO_NAME': 'pn2-msg', 'dropout': 0.5, 'cla_input_dim': 1024, 'act': 'relu'}}\n",
            "Arguments: <__main__.Options object at 0x7861ba528430>\n",
            "ModelNet40_OOD - Reading data from h5py file: /content/3D_OS/3D_OS_release_data/modelnet40_normal_resampled/ood_sets_cache/SR1_train.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/3D_OS/utils/rsmix_provider.py:157: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if len(label_batch.shape) is 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ModelNet40_OOD - split: train, categories: {'chair': 0, 'bookshelf': 1, 'door': 2, 'sink': 3, 'sofa': 4}\n",
            "SR1 train data len: 2378\n",
            "ModelNet40_OOD - Reading data from h5py file: /content/3D_OS/3D_OS_release_data/modelnet40_normal_resampled/ood_sets_cache/SR1_test.h5\n",
            "ModelNet40_OOD - split: test, categories: {'chair': 0, 'bookshelf': 1, 'door': 2, 'sink': 3, 'sofa': 4}\n",
            "Src is SR1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ScanObject - num_points: 10000, sonn_split: main_split, h5_suffix: objectdataset.h5, split: all, class_choice: {4: 0, 8: 1, 7: 2, 12: 3, 13: 4}, num samples: 1255\n",
            "ScanObject - num_points: 10000, sonn_split: main_split, h5_suffix: objectdataset.h5, split: all, class_choice: {10: 0, 14: 1, 5: 2, 6: 3, 9: 2}, num samples: 788\n",
            "ScanObject - num_points: 10000, sonn_split: main_split, h5_suffix: objectdataset.h5, split: all, class_choice: {0: 404, 1: 404, 2: 404, 3: 404, 11: 404}, num samples: 847\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
        "\n",
        "\n",
        "data_list = []\n",
        "label_list = []\n",
        "\n",
        "for data, label in train_loader_SR:\n",
        "    tensor_permuted = data.permute(0, 2, 1)\n",
        "    tensor_permuted = tensor_permuted.squeeze(0)\n",
        "    data_list.append(tensor_permuted)\n",
        "    label_list.append(label.item())\n",
        "print(len(data_list))\n",
        "print(len(label_list))\n",
        "for data, label in train_loader:\n",
        "    points = data[:, :, :3, :]\n",
        "    points = points.squeeze(1)\n",
        "    points = points.squeeze(0)\n",
        "    data_list.append(points)\n",
        "    label_list.append(label.item())\n",
        "\n",
        "print(len(data_list))\n",
        "print(len(label_list))\n",
        "print(label_list)\n",
        "BATCH_SIZE = 10\n",
        "combined_dataset = PointCloudDatasetWithLabels(data_list, label_list)\n",
        "\n",
        "combined_dataloader = DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf_j8-qxiqaV",
        "outputId": "8089f636-7ee9-4a62-a1e4-903a4ed68297"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2378\n",
            "2378\n",
            "2678\n",
            "2678\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(combined_dataloader, 0):\n",
        "    points, target = data\n",
        "    print(points.shape, \"   \", target)"
      ],
      "metadata": {
        "id": "_M8FDuiO0muQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99958112-42ca-40a6-b657-28e6afc61c4f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 3, 10000])     tensor([1, 3, 1, 4, 3, 0, 6, 0, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 4, 1, 3, 4, 0, 4, 1, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 4, 0, 4, 1, 0, 4, 0, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 4, 1, 0, 0, 0, 4, 1, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 1, 1, 0, 4, 1, 0, 6, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 3, 2, 0, 0, 0, 0, 1, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 3, 0, 3, 1, 0, 4, 1, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 0, 0, 4, 1, 6, 1, 1, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 0, 6, 6, 0, 4, 3, 6, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 1, 1, 4, 0, 4, 1, 1, 6, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 6, 4, 1, 1, 1, 3, 0, 6, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 3, 1, 2, 2, 0, 3, 6, 0, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 1, 6, 0, 2, 1, 0, 6, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 1, 4, 0, 4, 4, 2, 0, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 1, 0, 4, 0, 0, 4, 0, 1, 2])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 0, 0, 1, 0, 0, 6, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 1, 4, 1, 6, 1, 0, 0, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 4, 2, 0, 4, 4, 0, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 1, 4, 4, 0, 0, 4, 0, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([2, 1, 0, 0, 6, 4, 0, 4, 1, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([2, 4, 4, 1, 0, 0, 1, 0, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 1, 1, 4, 0, 4, 4, 4, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 4, 4, 1, 0, 0, 4, 4, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 1, 6, 0, 3, 0, 4, 0, 1, 2])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 1, 1, 0, 0, 0, 4, 6, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 1, 0, 0, 1, 3, 6, 6, 0, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 4, 1, 0, 1, 4, 1, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 6, 4, 4, 2, 0, 4, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 4, 0, 4, 0, 4, 4, 6, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 3, 4, 1, 6, 0, 6, 4, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 6, 1, 0, 4, 0, 1, 0, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 0, 6, 0, 0, 1, 4, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 6, 3, 1, 0, 6, 6, 0, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 4, 1, 1, 0, 2, 2, 4, 0, 2])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 1, 0, 1, 0, 0, 0, 1, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 2, 4, 6, 0, 1, 1, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 0, 3, 2, 3, 6, 0, 0, 6, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([3, 4, 0, 6, 3, 4, 0, 2, 3, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 4, 6, 1, 0, 3, 4, 1, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 1, 0, 0, 4, 1, 1, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 1, 4, 4, 4, 0, 4, 4, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 6, 6, 1, 4, 4, 4, 6, 0, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 0, 0, 4, 6, 1, 4, 1, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 2, 4, 1, 0, 1, 2, 1, 0, 2])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 6, 1, 1, 0, 1, 0, 0, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 4, 6, 4, 1, 1, 4, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 0, 6, 4, 0, 1, 6, 4, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 3, 0, 4, 4, 1, 0, 0, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 4, 0, 4, 1, 4, 0, 4, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 6, 0, 1, 6, 0, 4, 0, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([3, 2, 0, 0, 1, 0, 2, 1, 1, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 6, 1, 1, 0, 4, 0, 0, 4, 3])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 6, 6, 3, 6, 0, 1, 4, 6, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 4, 1, 4, 0, 0, 4, 4, 4, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 1, 2, 4, 4, 4, 6, 2, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 1, 0, 1, 0, 1, 0, 0, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 0, 0, 4, 0, 6, 0, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 6, 1, 0, 4, 1, 1, 3, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 3, 1, 6, 6, 1, 0, 2, 0, 2])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 0, 1, 0, 1, 4, 4, 4, 4, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 1, 0, 1, 2, 0, 0, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 2, 4, 1, 1, 0, 1, 3, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 3, 3, 3, 4, 4, 1, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 4, 1, 1, 1, 0, 4, 6, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 4, 0, 0, 6, 4, 0, 6, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 4, 0, 4, 4, 0, 1, 4, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 6, 1, 3, 4, 0, 1, 4, 6, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 0, 0, 4, 0, 1, 0, 4, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 4, 0, 6, 0, 4, 4, 6, 1, 3])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 1, 4, 1, 4, 4, 4, 0, 3])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 0, 1, 1, 6, 4, 0, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 1, 4, 2, 6, 4, 0, 4, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 4, 3, 4, 1, 4, 1, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 6, 4, 1, 3, 4, 4, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 0, 1, 1, 0, 1, 4, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 3, 0, 4, 0, 4, 0, 4, 1, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 4, 0, 4, 1, 4, 6, 6, 4, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 4, 4, 4, 4, 6, 1, 0, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 6, 6, 6, 0, 2, 4, 0, 3, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 6, 6, 4, 0, 4, 1, 6, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 1, 0, 4, 0, 4, 0, 6, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 4, 6, 4, 0, 0, 1, 4, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 4, 4, 1, 1, 4, 2, 1, 4, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([3, 4, 4, 0, 6, 6, 0, 4, 0, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 6, 1, 3, 0, 0, 0, 1, 1, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 0, 0, 0, 3, 4, 1, 6, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 1, 0, 0, 0, 1, 0, 4, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 1, 0, 0, 0, 1, 4, 4, 4, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 0, 0, 6, 1, 4, 0, 3, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 4, 0, 6, 0, 6, 0, 4, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 1, 1, 0, 2, 0, 1, 0, 2])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 1, 0, 0, 2, 1, 0, 2, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 4, 3, 4, 0, 0, 1, 4, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 6, 0, 6, 2, 0, 1, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 1, 2, 0, 1, 2, 6, 6, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 0, 3, 4, 1, 6, 6, 4, 0, 2])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 4, 4, 1, 0, 2, 0, 4, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 0, 0, 0, 6, 1, 0, 6, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 1, 0, 0, 0, 0, 0, 0, 4, 3])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 4, 4, 4, 0, 1, 1, 0, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 1, 6, 1, 4, 6, 1, 3, 1, 2])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 1, 1, 0, 4, 4, 1, 4, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([3, 1, 3, 0, 1, 4, 1, 1, 1, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 4, 0, 4, 0, 4, 4, 2, 6, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 3, 4, 0, 4, 1, 4, 0, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 3, 4, 1, 0, 0, 4, 4, 4, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 4, 4, 4, 1, 1, 6, 0, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 4, 0, 6, 4, 6, 3, 0, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 0, 0, 0, 1, 4, 0, 3, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 4, 4, 6, 1, 0, 3, 1, 4, 2])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 4, 0, 1, 4, 0, 4, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 4, 6, 6, 3, 3, 4, 0, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 2, 6, 4, 0, 0, 1, 0, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 6, 3, 0, 0, 3, 1, 0, 6, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 4, 4, 2, 4, 1, 4, 0, 3])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 4, 0, 4, 0, 6, 1, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 4, 4, 1, 4, 4, 0, 0, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 0, 6, 4, 0, 0, 1, 1, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 3, 0, 4, 4, 4, 0, 0, 6, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 0, 4, 6, 4, 4, 3, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 1, 1, 3, 6, 0, 0, 0, 1, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 6, 4, 4, 0, 1, 1, 1, 6, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 4, 6, 1, 1, 0, 2, 4, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 0, 6, 4, 1, 1, 0, 0, 4, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 0, 2, 3, 4, 4, 4, 4, 4, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 0, 0, 0, 1, 4, 6, 1, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 0, 0, 1, 0, 6, 0, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([2, 4, 4, 4, 1, 4, 1, 0, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([2, 4, 4, 2, 2, 0, 4, 1, 0, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 6, 6, 2, 0, 6, 0, 0, 0, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 3, 0, 4, 1, 0, 4, 4, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 0, 0, 0, 0, 4, 4, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([2, 1, 1, 4, 4, 1, 4, 0, 1, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 1, 1, 1, 4, 1, 0, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 0, 4, 0, 0, 4, 1, 0, 0, 3])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 4, 0, 6, 6, 0, 0, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 6, 3, 0, 1, 6, 6, 6, 2])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 6, 3, 0, 6, 4, 0, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 1, 1, 0, 6, 0, 1, 0, 3, 2])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 1, 6, 6, 4, 0, 4, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 4, 1, 6, 1, 4, 0, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 1, 3, 1, 0, 1, 4, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 6, 6, 1, 6, 0, 3, 4, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 4, 4, 4, 3, 6, 1, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 6, 0, 3, 1, 4, 6, 1, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 6, 0, 0, 0, 4, 6, 0, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 4, 4, 0, 0, 6, 0, 1, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 4, 4, 0, 0, 0, 0, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 4, 1, 1, 0, 4, 0, 4, 0, 2])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 1, 1, 4, 1, 0, 0, 6, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 1, 1, 0, 4, 4, 1, 1, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 1, 4, 0, 4, 0, 4, 4, 1, 3])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 0, 4, 6, 4, 1, 4, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 2, 0, 4, 0, 0, 0, 2, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 1, 0, 2, 0, 0, 4, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 2, 0, 4, 0, 0, 0, 4, 1, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 0, 0, 1, 0, 1, 0, 1, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 4, 6, 6, 6, 6, 2, 6, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 0, 4, 0, 0, 2, 0, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 0, 4, 0, 4, 1, 1, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 1, 1, 0, 4, 0, 4, 4, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 4, 4, 1, 4, 1, 0, 4, 0, 2])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 2, 4, 0, 6, 0, 3, 0, 4, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 0, 6, 0, 3, 1, 4, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([2, 1, 0, 0, 1, 0, 4, 0, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 4, 1, 1, 1, 1, 0, 1, 4, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 3, 4, 0, 0, 4, 0, 3, 2])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 1, 6, 4, 1, 1, 4, 2, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([3, 4, 6, 0, 6, 0, 4, 0, 0, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 3, 0, 0, 1, 1, 1, 4, 6, 2])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 4, 4, 4, 1, 6, 1, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 0, 4, 6, 4, 0, 0, 6, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 4, 2, 4, 4, 4, 0, 0, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 3, 0, 4, 0, 4, 4, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 2, 1, 2, 4, 6, 4, 3, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([2, 0, 4, 4, 0, 4, 4, 0, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([3, 0, 2, 0, 4, 1, 1, 0, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 0, 0, 0, 4, 2, 1, 4, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 6, 4, 4, 0, 0, 4, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 1, 0, 2, 1, 2, 0, 0, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 0, 4, 0, 0, 1, 1, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 0, 4, 6, 4, 1, 4, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 4, 0, 1, 0, 4, 4, 0, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 1, 0, 0, 2, 1, 3, 1, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 3, 1, 4, 1, 0, 2, 0, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 6, 0, 0, 3, 3, 0, 6, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 6, 4, 1, 2, 4, 1, 0, 3, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 1, 1, 6, 6, 4, 0, 0, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 0, 4, 4, 2, 6, 0, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 0, 1, 0, 0, 0, 1, 4, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 4, 3, 0, 0, 1, 1, 4, 1, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 1, 0, 3, 1, 1, 0, 4, 4, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 1, 0, 1, 4, 0, 0, 4, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 1, 0, 4, 0, 1, 1, 0, 1, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 1, 4, 1, 6, 4, 0, 4, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 4, 4, 1, 0, 4, 1, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 6, 0, 6, 0, 0, 4, 1, 6, 3])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 6, 1, 0, 1, 6, 4, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 4, 4, 1, 1, 4, 1, 1, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 4, 4, 0, 6, 4, 1, 4, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 1, 1, 0, 6, 4, 0, 4, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 0, 0, 0, 0, 1, 1, 6, 4, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 4, 0, 0, 6, 0, 4, 1, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([3, 0, 6, 3, 0, 4, 4, 4, 4, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 3, 4, 2, 4, 2, 4, 0, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 1, 1, 4, 0, 1, 0, 3, 4, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 3, 4, 6, 0, 4, 6, 4, 1, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 6, 1, 0, 0, 4, 1, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 1, 0, 1, 0, 4, 1, 0, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 6, 0, 0, 0, 6, 1, 6, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 2, 1, 6, 3, 6, 4, 0, 6, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 0, 6, 1, 4, 4, 2, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 6, 4, 1, 4, 1, 0, 6, 6, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 1, 1, 1, 4, 0, 1, 1, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([3, 6, 3, 4, 1, 4, 0, 2, 0, 2])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 0, 4, 0, 0, 4, 0, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 0, 0, 6, 0, 1, 1, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 3, 4, 3, 1, 6, 2, 6, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([3, 4, 3, 4, 0, 0, 0, 0, 6, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 4, 0, 6, 0, 4, 0, 1, 6, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 0, 0, 0, 1, 0, 4, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 6, 4, 0, 4, 4, 6, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 3, 4, 6, 4, 0, 0, 0, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 3, 4, 4, 6, 6, 2, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 6, 0, 6, 1, 1, 4, 4, 2, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 6, 3, 1, 0, 6, 4, 2, 2, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 1, 3, 0, 6, 4, 0, 0, 1, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 4, 1, 3, 4, 3, 1, 1, 6, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 1, 3, 1, 0, 0, 0, 2, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 1, 0, 0, 0, 4, 3, 1, 4, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 6, 4, 0, 6, 0, 4, 3, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 4, 4, 6, 0, 6, 0, 1, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 2, 0, 0, 6, 4, 1, 0, 4, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 6, 1, 0, 4, 0, 0, 1, 0, 3])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 4, 0, 1, 6, 4, 3, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 1, 0, 2, 4, 1, 4, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 4, 0, 0, 4, 0, 1, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 2, 1, 4, 0, 0, 0, 6, 0, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 0, 1, 4, 4, 4, 1, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 6, 3, 4, 4, 2, 4, 1, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([3, 3, 0, 6, 4, 1, 0, 0, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 0, 0, 4, 1, 1, 4, 6, 1, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 3, 0, 1, 4, 4, 0, 0, 6, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 4, 4, 1, 1, 3, 0, 4, 6, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 4, 0, 4, 3, 0, 0, 2, 1, 3])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 1, 0, 1, 0, 1, 4, 4, 6, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 4, 1, 4, 1, 1, 4, 4, 1, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 1, 0, 1, 0, 4, 4, 4, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 6, 6, 6, 4, 2, 4, 1, 0, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([1, 3, 4, 0, 0, 2, 0, 0, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 3, 1, 1, 4, 4, 1, 0, 2, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 4, 6, 1, 4, 0, 0, 4, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 0, 6, 1, 3, 0, 0, 2, 2])\n",
            "torch.Size([10, 3, 10000])     tensor([2, 4, 6, 0, 6, 0, 6, 6, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 4, 0, 1, 1, 1, 4, 4, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 4, 4, 1, 1, 1, 3, 4, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 6, 0, 0, 1, 0, 0, 0, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 6, 4, 1, 0, 0, 0, 3, 1, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 4, 1, 4, 0, 0, 6, 2, 1])\n",
            "torch.Size([10, 3, 10000])     tensor([6, 0, 4, 0, 4, 1, 0, 1, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([2, 4, 1, 4, 0, 4, 0, 4, 0, 0])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 1, 0, 0, 1, 1, 1, 0, 4, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 1, 0, 4, 4, 0, 0, 1, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 0, 0, 4, 4, 2, 1, 3, 4, 4])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 2, 1, 1, 0, 0, 0, 1, 0, 2])\n",
            "torch.Size([10, 3, 10000])     tensor([0, 0, 3, 0, 0, 1, 4, 4, 1, 6])\n",
            "torch.Size([10, 3, 10000])     tensor([4, 1, 4, 6, 1, 4, 1, 4, 3, 2])\n",
            "torch.Size([8, 3, 10000])     tensor([1, 0, 3, 1, 1, 0, 3, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create PointNet model"
      ],
      "metadata": {
        "id": "n59YTBCVSCLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class STN3d(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(STN3d, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
        "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 9)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "        self.bn4 = nn.BatchNorm1d(512)\n",
        "        self.bn5 = nn.BatchNorm1d(256)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.size()[0]\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = torch.max(x, 2, keepdim=True)[0]\n",
        "        x = x.view(-1, 1024)\n",
        "\n",
        "        x = F.relu(self.bn4(self.fc1(x)))\n",
        "        x = F.relu(self.bn5(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        iden = Variable(torch.from_numpy(np.array([1,0,0,0,1,0,0,0,1]).astype(np.float32))).view(1,9).repeat(batchsize,1)\n",
        "        if x.is_cuda:\n",
        "            iden = iden.cuda()\n",
        "        x = x + iden\n",
        "        x = x.view(-1, 3, 3)\n",
        "        return x\n",
        "\n",
        "\n",
        "class STNkd(nn.Module):\n",
        "    def __init__(self, k=64):\n",
        "        super(STNkd, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv1d(k, 64, 1)\n",
        "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, k*k)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "        self.bn4 = nn.BatchNorm1d(512)\n",
        "        self.bn5 = nn.BatchNorm1d(256)\n",
        "\n",
        "        self.k = k\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.size()[0]\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = torch.max(x, 2, keepdim=True)[0]\n",
        "        x = x.view(-1, 1024)\n",
        "\n",
        "        x = F.relu(self.bn4(self.fc1(x)))\n",
        "        x = F.relu(self.bn5(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        iden = Variable(torch.from_numpy(np.eye(self.k).flatten().astype(np.float32))).view(1,self.k*self.k).repeat(batchsize,1)\n",
        "        if x.is_cuda:\n",
        "            iden = iden.cuda()\n",
        "        x = x + iden\n",
        "        x = x.view(-1, self.k, self.k)\n",
        "        return x\n",
        "\n",
        "class PointNetfeat(nn.Module):\n",
        "    def __init__(self, global_feat = True, feature_transform = False):\n",
        "        super(PointNetfeat, self).__init__()\n",
        "        self.stn = STN3d()\n",
        "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
        "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "        self.global_feat = global_feat\n",
        "        self.feature_transform = feature_transform\n",
        "        if self.feature_transform:\n",
        "            self.fstn = STNkd(k=64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        n_pts = x.size()[2]\n",
        "        trans = self.stn(x)\n",
        "        x = x.transpose(2, 1)\n",
        "        x = torch.bmm(x, trans)\n",
        "        x = x.transpose(2, 1)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        if self.feature_transform:\n",
        "            trans_feat = self.fstn(x)\n",
        "            x = x.transpose(2,1)\n",
        "            x = torch.bmm(x, trans_feat)\n",
        "            x = x.transpose(2,1)\n",
        "        else:\n",
        "            trans_feat = None\n",
        "\n",
        "        pointfeat = x\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.bn3(self.conv3(x))\n",
        "        x = torch.max(x, 2, keepdim=True)[0]\n",
        "        x = x.view(-1, 1024)\n",
        "        if self.global_feat:\n",
        "            return x, trans, trans_feat\n",
        "        else:\n",
        "            x = x.view(-1, 1024, 1).repeat(1, 1, n_pts)\n",
        "            return torch.cat([x, pointfeat], 1), trans, trans_feat\n",
        "\n",
        "class PointNetCls(nn.Module):\n",
        "    def __init__(self, k=2, feature_transform=False):\n",
        "        super(PointNetCls, self).__init__()\n",
        "        self.feature_transform = feature_transform\n",
        "        self.feat = PointNetfeat(global_feat=True, feature_transform=feature_transform)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, k)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, trans, trans_feat = self.feat(x)\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = F.relu(self.bn2(self.dropout(self.fc2(x))))\n",
        "        x = self.fc3(x)\n",
        "        return F.log_softmax(x, dim=1), trans, trans_feat\n",
        "\n",
        "    def get_feature_space_of_last_layer(self, x):\n",
        "        x, trans, trans_feat = self.feat(x)\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = F.relu(self.bn2(self.dropout(self.fc2(x))))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class PointNetDenseCls(nn.Module):\n",
        "    def __init__(self, k = 2, feature_transform=False):\n",
        "        super(PointNetDenseCls, self).__init__()\n",
        "        self.k = k\n",
        "        self.feature_transform=feature_transform\n",
        "        self.feat = PointNetfeat(global_feat=False, feature_transform=feature_transform)\n",
        "        self.conv1 = torch.nn.Conv1d(1088, 512, 1)\n",
        "        self.conv2 = torch.nn.Conv1d(512, 256, 1)\n",
        "        self.conv3 = torch.nn.Conv1d(256, 128, 1)\n",
        "        self.conv4 = torch.nn.Conv1d(128, self.k, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.size()[0]\n",
        "        n_pts = x.size()[2]\n",
        "        x, trans, trans_feat = self.feat(x)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.conv4(x)\n",
        "        x = x.transpose(2,1).contiguous()\n",
        "        x = F.log_softmax(x.view(-1,self.k), dim=-1)\n",
        "        x = x.view(batchsize, n_pts, self.k)\n",
        "        return x, trans, trans_feat\n",
        "\n",
        "def feature_transform_regularizer(trans):\n",
        "    d = trans.size()[1]\n",
        "    batchsize = trans.size()[0]\n",
        "    I = torch.eye(d)[None, :, :]\n",
        "    if trans.is_cuda:\n",
        "        I = I.cuda()\n",
        "    loss = torch.mean(torch.norm(torch.bmm(trans, trans.transpose(2,1)) - I, dim=(1,2)))\n",
        "    return loss\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sim_data = Variable(torch.rand(32,3,2500))\n",
        "    trans = STN3d()\n",
        "    out = trans(sim_data)\n",
        "    print('stn', out.size())\n",
        "    print('loss', feature_transform_regularizer(out))\n",
        "\n",
        "    sim_data_64d = Variable(torch.rand(32, 64, 2500))\n",
        "    trans = STNkd(k=64)\n",
        "    out = trans(sim_data_64d)\n",
        "    print('stn64d', out.size())\n",
        "    print('loss', feature_transform_regularizer(out))\n",
        "\n",
        "    pointfeat = PointNetfeat(global_feat=True)\n",
        "    out, _, _ = pointfeat(sim_data)\n",
        "    print('global feat', out.size())\n",
        "\n",
        "    pointfeat = PointNetfeat(global_feat=False)\n",
        "    out, _, _ = pointfeat(sim_data)\n",
        "    print('point feat', out.size())\n",
        "\n",
        "    cls = PointNetCls(k = 5)\n",
        "    out, _, _ = cls(sim_data)\n",
        "    print('class', out.size())\n",
        "\n",
        "    seg = PointNetDenseCls(k = 3)\n",
        "    out, _, _ = seg(sim_data)\n",
        "    print('seg', out.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw8ec2CsIjv0",
        "outputId": "c1d20251-f692-411a-efcf-e7e756590b71"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stn torch.Size([32, 3, 3])\n",
            "loss tensor(1.8352, grad_fn=<MeanBackward0>)\n",
            "stn64d torch.Size([32, 64, 64])\n",
            "loss tensor(124.9212, grad_fn=<MeanBackward0>)\n",
            "global feat torch.Size([32, 1024])\n",
            "point feat torch.Size([32, 1088, 2500])\n",
            "class torch.Size([32, 5])\n",
            "seg torch.Size([32, 2500, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/pointnet.pytorch\n",
        "!pip install -e .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAajhmAiVfa9",
        "outputId": "5891c1cf-891f-45b2-bd3f-53f39ec33522"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pointnet.pytorch\n",
            "Obtaining file:///content/pointnet.pytorch\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pointnet==0.0.1) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pointnet==0.0.1) (4.66.2)\n",
            "Collecting plyfile (from pointnet==0.0.1)\n",
            "  Downloading plyfile-1.0.3-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from plyfile->pointnet==0.0.1) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pointnet==0.0.1) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pointnet==0.0.1) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pointnet==0.0.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pointnet==0.0.1) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pointnet==0.0.1) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pointnet==0.0.1) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->pointnet==0.0.1) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pointnet==0.0.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pointnet==0.0.1) (1.3.0)\n",
            "Installing collected packages: plyfile, pointnet\n",
            "  Running setup.py develop for pointnet\n",
            "Successfully installed plyfile-1.0.3 pointnet-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model"
      ],
      "metadata": {
        "id": "i9UtYrd9SIyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from pointnet.dataset import ShapeNetDataset, ModelNetDataset\n",
        "from pointnet.model import feature_transform_regularizer\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "dataloader = combined_dataloader\n",
        "\n",
        "testdataloader = combined_dataloader\n",
        "\n",
        "batch_size = BATCH_SIZE\n",
        "\n",
        "classifier = PointNetCls(k=7, feature_transform=False)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "classifier.to(\"cuda\")\n",
        "\n",
        "num_batch = len(dataloader) / 1\n",
        "\n",
        "nepoch = 65\n",
        "for epoch in range(nepoch):\n",
        "    scheduler.step()\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        points, target = data\n",
        "        #points = points[:, :, :3, :]\n",
        "        #points = points.squeeze(1)\n",
        "        #points = points.transpose(2, 1)\n",
        "        points, target = points.cuda(), target.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        classifier = classifier.train()\n",
        "        pred, trans, trans_feat = classifier(points)\n",
        "        loss = F.nll_loss(pred, target)\n",
        "        #if opt.feature_transform:\n",
        "        #    loss += feature_transform_regularizer(trans_feat) * 0.001\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pred_choice = pred.data.max(1)[1]\n",
        "        correct = pred_choice.eq(target.data).cpu().sum()\n",
        "        print('[%d: %d/%d] train loss: %f accuracy: %f' % (epoch, i, num_batch, loss.item(), correct.item() / float(batch_size)))\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            j, data = next(enumerate(testdataloader, 0))\n",
        "            points, target = data\n",
        "            #points = points[:, :, :3, :]\n",
        "            #points = points.squeeze(1)\n",
        "            #target = target[:, 0]\n",
        "            #points = points.transpose(2, 1)\n",
        "            points, target = points.cuda(), target.cuda()\n",
        "            classifier = classifier.eval()\n",
        "            pred, _, _ = classifier(points)\n",
        "            loss = F.nll_loss(pred, target)\n",
        "            pred_choice = pred.data.max(1)[1]\n",
        "            correct = pred_choice.eq(target.data).cpu().sum()\n",
        "            print('[%d: %d/%d] %s loss: %f accuracy: %f' % (epoch, i, num_batch, 'test', loss.item(), correct.item()/float(batch_size)))\n",
        "\n",
        "torch.save(classifier.state_dict(), str(\"PointNetmodel\"))\n",
        "\n",
        "total_correct = 0\n",
        "total_testset = 0\n",
        "for i,data in tqdm(enumerate(testdataloader, 0)):\n",
        "    points, target = data\n",
        "    target = target[:, 0]\n",
        "    points = points.transpose(2, 1)\n",
        "    points, target = points.cuda(), target.cuda()\n",
        "    classifier = classifier.eval()\n",
        "    pred, _, _ = classifier(points)\n",
        "    pred_choice = pred.data.max(1)[1]\n",
        "    correct = pred_choice.eq(target.data).cpu().sum()\n",
        "    total_correct += correct.item()\n",
        "    total_testset += points.size()[0]\n",
        "\n",
        "print(\"final accuracy {}\".format(total_correct / float(total_testset)))"
      ],
      "metadata": {
        "id": "XdqQ1bmqTu1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.save(classifier.state_dict(), str(\"PointNetmodel\"))"
      ],
      "metadata": {
        "id": "n4p_rdK_Ss6e"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_classifier = torch.load(\"PointNetmodel\")\n",
        "model = classifier"
      ],
      "metadata": {
        "id": "k2xYTycEJfjy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "model.eval()\n",
        "device = torch.device(\"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "def run_data_through_model_and_save_data(dataloader, model, filename, save_dir):\n",
        "    print(\"Running training data through the model\")\n",
        "    feats = []\n",
        "    for i, (data, label) in tqdm(enumerate(dataloader)):\n",
        "\n",
        "        data = data.to(device)\n",
        "        data = data.squeeze(0)\n",
        "        data = data[:, :3, :]\n",
        "\n",
        "        output_feat = model.get_feature_space_of_last_layer(data)\n",
        "\n",
        "        feats.append(output_feat.detach().numpy())\n",
        "\n",
        "    outfile = save_dir + \"/\" + filename + \".npy\"\n",
        "    np.save(outfile, np.array(feats))\n",
        "    print(\"Saved data to \" + outfile)\n",
        "    return feats\n",
        "\n",
        "%cd /content\n",
        "save_dir = \"Extension_outputs_with_different_distortions_Point_Net\"\n",
        "if not os.path.exists(save_dir):\n",
        "    print(f\"Creating directory: {save_dir}\")\n",
        "    os.makedirs(save_dir)"
      ],
      "metadata": {
        "id": "ni0PibGBJk79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32207ba-8fa8-400d-925f-aa1e3efd35aa"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Creating directory: Extension_outputs_with_different_distortions_Point_Net\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load chair\n",
        "points = np.load(\"/content/output_point_cloud.npy\")\n",
        "points = torch.from_numpy(points)\n",
        "points = points.reshape(-1, 3)\n",
        "\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(points)\n",
        "\n",
        "# Create a defect point cloud\n",
        "number_of_samples_per_defect = 300\n",
        "type_of_defects = [\"distort\", \"remove parts\", \"scale\", \"add noise\", \"asymmetrical\"]\n",
        "defect_chairs_distort = generate_defect_chairs(pcd, [\"distort\"], number_of_noisy_chairs=number_of_samples_per_defect)\n",
        "defect_chairs_remove_parts = generate_defect_chairs(pcd, [\"remove parts\"], number_of_noisy_chairs=number_of_samples_per_defect)\n",
        "defect_chairs_scale = generate_defect_chairs(pcd, [\"scale\"], number_of_noisy_chairs=number_of_samples_per_defect)\n",
        "defect_chairs_add_noise = generate_defect_chairs(pcd, [\"add noise\"], number_of_noisy_chairs=number_of_samples_per_defect)\n",
        "defect_chairs_asymmetrical = generate_defect_chairs(pcd, [\"asymmetrical\"], number_of_noisy_chairs=number_of_samples_per_defect)\n",
        "\n",
        "# Create labels\n",
        "defect_chairs_distort_labels = [\"distort\"] * number_of_samples_per_defect\n",
        "defect_chairs_remove_parts_labels = [\"remove parts\"] * number_of_samples_per_defect\n",
        "defect_chairs_scale_labels = [\"scale\"] * number_of_samples_per_defect\n",
        "defect_chairs_add_noise_labels = [\"add noise\"] * number_of_samples_per_defect\n",
        "defect_chairs_asymmetrical_labels = [\"asymmetrical\"] * number_of_samples_per_defect\n",
        "\n",
        "# Filter for OpenShape\n",
        "for i in range(0, number_of_samples_per_defect):\n",
        "    _, defect_chairs_distort[i] = filter_for_OpenShape(defect_chairs_distort[i], num_points=10000)\n",
        "    _, defect_chairs_remove_parts[i] = filter_for_OpenShape(defect_chairs_remove_parts[i], num_points=10000)\n",
        "    _, defect_chairs_scale[i] = filter_for_OpenShape(defect_chairs_scale[i], num_points=10000)\n",
        "    _, defect_chairs_add_noise[i] = filter_for_OpenShape(defect_chairs_add_noise[i], num_points=10000)\n",
        "    _, defect_chairs_asymmetrical[i] = filter_for_OpenShape(defect_chairs_asymmetrical[i], num_points=10000)\n",
        "\n",
        "# Create datasets\n",
        "defect_chairs_distort_dataset = PointCloudDatasetWithLabels(defect_chairs_distort, defect_chairs_distort_labels)\n",
        "defect_chairs_remove_parts_dataset = PointCloudDatasetWithLabels(defect_chairs_remove_parts, defect_chairs_remove_parts_labels)\n",
        "defect_chairs_scale_dataset = PointCloudDatasetWithLabels(defect_chairs_scale, defect_chairs_scale_labels)\n",
        "defect_chairs_add_noise_dataset = PointCloudDatasetWithLabels(defect_chairs_add_noise, defect_chairs_add_noise_labels)\n",
        "defect_chairs_asymmetrical_dataset = PointCloudDatasetWithLabels(defect_chairs_asymmetrical, defect_chairs_asymmetrical_labels)\n",
        "\n",
        "# Create dataloaders\n",
        "defect_chairs_distort_loader = DataLoader(defect_chairs_distort_dataset, batch_size=1, shuffle=False, num_workers=2)\n",
        "defect_chairs_remove_parts_loader = DataLoader(defect_chairs_remove_parts_dataset, batch_size=1, shuffle=False, num_workers=2)\n",
        "defect_chairs_scale_loader = DataLoader(defect_chairs_scale_dataset, batch_size=1, shuffle=False, num_workers=2)\n",
        "defect_chairs_add_noise_loader = DataLoader(defect_chairs_add_noise_dataset, batch_size=1, shuffle=False, num_workers=2)\n",
        "defect_chairs_asymmetrical_loader = DataLoader(defect_chairs_asymmetrical_dataset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "# Run data through PointNet\n",
        "\n",
        "defect_chairs_distort_feats = run_data_through_model_and_save_data(defect_chairs_distort_loader, model, \"defect_chairs_distort_feats\", save_dir)\n",
        "defect_chairs_remove_parts_feats = run_data_through_model_and_save_data(defect_chairs_remove_parts_loader, model, \"defect_chairs_remove_parts_feats\", save_dir)\n",
        "defect_chairs_scale_feats = run_data_through_model_and_save_data(defect_chairs_scale_loader, model, \"defect_chairs_scale_feats\", save_dir)\n",
        "defect_chairs_add_noise_feats = run_data_through_model_and_save_data(defect_chairs_add_noise_loader, model, \"defect_chairs_add_noise_feats\", save_dir)\n",
        "defect_chairs_asymmetrical_feats = run_data_through_model_and_save_data(defect_chairs_asymmetrical_loader, model, \"defect_chairs_asymmetrical_feats\", save_dir)\n",
        "\n",
        "train_feats = run_data_through_model_and_save_data(train_loader, model, \"train_feats\", save_dir)\n",
        "src_feats = run_data_through_model_and_save_data(id_loader, model, \"src_feats\", save_dir)\n",
        "\n",
        "train_feats = np.load(\"Extension_outputs_with_different_distortions_Point_Net/train_feats.npy\")\n",
        "src_feats = np.load(\"Extension_outputs_with_different_distortions_Point_Net/src_feats.npy\")\n",
        "defect_chairs_distort_feats = np.load(\"/content/Extension_outputs_with_different_distortions_Point_Net/defect_chairs_distort_feats.npy\")\n",
        "defect_chairs_remove_parts_feats = np.load(\"/content/Extension_outputs_with_different_distortions_Point_Net/defect_chairs_remove_parts_feats.npy\")\n",
        "defect_chairs_scale_feats = np.load(\"/content/Extension_outputs_with_different_distortions_Point_Net/defect_chairs_scale_feats.npy\")\n",
        "defect_chairs_add_noise_feats = np.load(\"/content/Extension_outputs_with_different_distortions_Point_Net/defect_chairs_add_noise_feats.npy\")\n",
        "defect_chairs_asymmetrical_feats = np.load(\"/content/Extension_outputs_with_different_distortions_Point_Net/defect_chairs_asymmetrical_feats.npy\")\n",
        "\n",
        "train_feats = torch.from_numpy(train_feats)\n",
        "src_feats = torch.from_numpy(src_feats)\n",
        "defect_chairs_distort_feats = torch.from_numpy(defect_chairs_distort_feats)\n",
        "defect_chairs_remove_parts_feats = torch.from_numpy(defect_chairs_remove_parts_feats)\n",
        "defect_chairs_scale_feats = torch.from_numpy(defect_chairs_scale_feats)\n",
        "defect_chairs_add_noise_feats = torch.from_numpy(defect_chairs_add_noise_feats)\n",
        "defect_chairs_asymmetrical_feats = torch.from_numpy(defect_chairs_asymmetrical_feats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "sGIDOUhpM2--",
        "outputId": "df287d77-31ba-434d-9446-ea9d127fb8a7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running training data through the OpenShape model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "300it [01:26,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved data to Extension_outputs_with_different_distortions_Point_Net/defect_chairs_distort_feats.npy\n",
            "Running training data through the OpenShape model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "300it [01:19,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved data to Extension_outputs_with_different_distortions_Point_Net/defect_chairs_remove_parts_feats.npy\n",
            "Running training data through the OpenShape model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "300it [01:13,  4.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved data to Extension_outputs_with_different_distortions_Point_Net/defect_chairs_scale_feats.npy\n",
            "Running training data through the OpenShape model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "300it [01:13,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved data to Extension_outputs_with_different_distortions_Point_Net/defect_chairs_add_noise_feats.npy\n",
            "Running training data through the OpenShape model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "300it [01:11,  4.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved data to Extension_outputs_with_different_distortions_Point_Net/defect_chairs_asymmetrical_feats.npy\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "run_data_through_model_and_save_data() missing 1 required positional argument: 'save_dir'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-8a2ff2c7be98>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mdefect_chairs_asymmetrical_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_data_through_model_and_save_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefect_chairs_asymmetrical_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"defect_chairs_asymmetrical_feats\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mtrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_data_through_model_and_save_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_feats\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0msrc_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_data_through_model_and_save_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"src_feats\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: run_data_through_model_and_save_data() missing 1 required positional argument: 'save_dir'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_feats = np.load(\"Extension_outputs_with_different_distortions_Point_Net/train_feats.npy\")\n",
        "src_feats = np.load(\"Extension_outputs_with_different_distortions_Point_Net/src_feats.npy\")\n",
        "defect_chairs_distort_feats = np.load(\"/content/Extension_outputs_with_different_distortions_Point_Net/defect_chairs_distort_feats.npy\")\n",
        "defect_chairs_remove_parts_feats = np.load(\"/content/Extension_outputs_with_different_distortions_Point_Net/defect_chairs_remove_parts_feats.npy\")\n",
        "defect_chairs_scale_feats = np.load(\"/content/Extension_outputs_with_different_distortions_Point_Net/defect_chairs_scale_feats.npy\")\n",
        "defect_chairs_add_noise_feats = np.load(\"/content/Extension_outputs_with_different_distortions_Point_Net/defect_chairs_add_noise_feats.npy\")\n",
        "defect_chairs_asymmetrical_feats = np.load(\"/content/Extension_outputs_with_different_distortions_Point_Net/defect_chairs_asymmetrical_feats.npy\")\n",
        "\n",
        "train_feats = torch.from_numpy(train_feats)\n",
        "src_feats = torch.from_numpy(src_feats)\n",
        "defect_chairs_distort_feats = torch.from_numpy(defect_chairs_distort_feats)\n",
        "defect_chairs_remove_parts_feats = torch.from_numpy(defect_chairs_remove_parts_feats)\n",
        "defect_chairs_scale_feats = torch.from_numpy(defect_chairs_scale_feats)\n",
        "defect_chairs_add_noise_feats = torch.from_numpy(defect_chairs_add_noise_feats)\n",
        "defect_chairs_asymmetrical_feats = torch.from_numpy(defect_chairs_asymmetrical_feats)\n",
        "\n",
        "# Evaluate model\n",
        "from knn_cuda import KNN\n",
        "%cd /content/3D_OS\n",
        "from utils.ood_utils import eval_ood_sncore\n",
        "%cd /content\n",
        "\n",
        "knn = KNN(k=1, transpose_mode=True)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "train_feats = train_feats.to(device)\n",
        "src_feats = src_feats.to(device)\n",
        "defect_chairs_distort_feats = defect_chairs_distort_feats.to(device)\n",
        "defect_chairs_remove_parts_feats = defect_chairs_remove_parts_feats.to(device)\n",
        "defect_chairs_scale_feats = defect_chairs_scale_feats.to(device)\n",
        "defect_chairs_add_noise_feats = defect_chairs_add_noise_feats.to(device)\n",
        "defect_chairs_asymmetrical_feats = defect_chairs_asymmetrical_feats.to(device)\n",
        "\n",
        "\n",
        "def print_CeL2_scores(train_feats, src_feats, ood_feats):\n",
        "    print(\"Euclidean distances in a non-normalized space:\")\n",
        "    # eucl distance in a non-normalized space\n",
        "    src_dist, src_ids = knn(train_feats.unsqueeze(1), src_feats.unsqueeze(1))\n",
        "    src_dist = src_dist.squeeze().cpu()\n",
        "    src_scores = 1 / src_dist\n",
        "\n",
        "    ood_dist, _ = knn(train_feats.unsqueeze(0), ood_feats.unsqueeze(0))\n",
        "    ood_dist = ood_dist.squeeze().cpu()\n",
        "    ood_scores = 1 / ood_dist\n",
        "\n",
        "    # Scores for distort\n",
        "    eval_ood_sncore(\n",
        "        scores_list=[src_scores, ood_scores, ood_scores],\n",
        "        preds_list=[None, None, None],  # [src_pred, None, None],\n",
        "        labels_list=[None, None, None],  # [src_labels, None, None],\n",
        "        src_label=1  # confidence should be higher for ID samples\n",
        "    )\n",
        "# Print scores\n",
        "print(\"defect_chairs_distort_feats\")\n",
        "print_CeL2_scores(train_feats, src_feats, defect_chairs_distort_feats)\n",
        "print(\"defect_chairs_remove_parts_feats\")\n",
        "print_CeL2_scores(train_feats, src_feats, defect_chairs_remove_parts_feats)\n",
        "print(\"defect_chairs_scale_feats\")\n",
        "print_CeL2_scores(train_feats, src_feats, defect_chairs_scale_feats)\n",
        "print(\"defect_chairs_add_noise_feats\")\n",
        "print_CeL2_scores(train_feats, src_feats, defect_chairs_add_noise_feats)\n",
        "print(\"defect_chairs_asymmetrical_feats\")\n",
        "print_CeL2_scores(train_feats, src_feats, defect_chairs_asymmetrical_feats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEBB8VKSNLFM",
        "outputId": "3f0a4d80-885c-4b77-b198-92ea624adbf4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/3D_OS\n",
            "/content\n",
            "defect_chairs_distort_feats\n",
            "Euclidean distances in a non-normalized space:\n",
            "AUROC - Src label: 1, Tar label: 0\n",
            "SRC->TAR1:      AUROC: 0.9969, FPR95: 0.0033, AUPR_IN: 0.9905, AUPR_OUT: 0.9984\n",
            "SRC->TAR2:      AUROC: 0.9969, FPR95: 0.0033, AUPR_IN: 0.9905, AUPR_OUT: 0.9984\n",
            "SRC->TAR1+TAR2: AUROC: 0.9969, FPR95: 0.0033, AUPR_IN: 0.9814, AUPR_OUT: 0.9989\n",
            "to spreadsheet: 0.99685,0.0033333333333333335,0.9905137013701473,0.9983790738910072,0.99685,0.0033333333333333335,0.9905137013701473,0.9983790738910072,0.99685,0.0033333333333333335,0.981376531821309,0.9989291785866534\n",
            "defect_chairs_remove_parts_feats\n",
            "Euclidean distances in a non-normalized space:\n",
            "AUROC - Src label: 1, Tar label: 0\n",
            "SRC->TAR1:      AUROC: 1.0000, FPR95: 0.0000, AUPR_IN: 1.0000, AUPR_OUT: 1.0000\n",
            "SRC->TAR2:      AUROC: 1.0000, FPR95: 0.0000, AUPR_IN: 1.0000, AUPR_OUT: 1.0000\n",
            "SRC->TAR1+TAR2: AUROC: 1.0000, FPR95: 0.0000, AUPR_IN: 1.0000, AUPR_OUT: 1.0000\n",
            "to spreadsheet: 1.0,0.0,1.0,1.0,1.0,0.0,1.0,1.0,1.0,0.0,1.0,1.0\n",
            "defect_chairs_scale_feats\n",
            "Euclidean distances in a non-normalized space:\n",
            "AUROC - Src label: 1, Tar label: 0\n",
            "SRC->TAR1:      AUROC: 1.0000, FPR95: 0.0000, AUPR_IN: 1.0000, AUPR_OUT: 1.0000\n",
            "SRC->TAR2:      AUROC: 1.0000, FPR95: 0.0000, AUPR_IN: 1.0000, AUPR_OUT: 1.0000\n",
            "SRC->TAR1+TAR2: AUROC: 1.0000, FPR95: 0.0000, AUPR_IN: 1.0000, AUPR_OUT: 1.0000\n",
            "to spreadsheet: 1.0,0.0,1.0,1.0,1.0,0.0,1.0,1.0,1.0,0.0,1.0,1.0\n",
            "defect_chairs_add_noise_feats\n",
            "Euclidean distances in a non-normalized space:\n",
            "AUROC - Src label: 1, Tar label: 0\n",
            "SRC->TAR1:      AUROC: 1.0000, FPR95: 0.0000, AUPR_IN: 1.0000, AUPR_OUT: 1.0000\n",
            "SRC->TAR2:      AUROC: 1.0000, FPR95: 0.0000, AUPR_IN: 1.0000, AUPR_OUT: 1.0000\n",
            "SRC->TAR1+TAR2: AUROC: 1.0000, FPR95: 0.0000, AUPR_IN: 1.0000, AUPR_OUT: 1.0000\n",
            "to spreadsheet: 1.0,0.0,1.0,1.0,1.0,0.0,1.0,1.0,1.0,0.0,1.0,1.0\n",
            "defect_chairs_asymmetrical_feats\n",
            "Euclidean distances in a non-normalized space:\n",
            "AUROC - Src label: 1, Tar label: 0\n",
            "SRC->TAR1:      AUROC: 0.9975, FPR95: 0.0033, AUPR_IN: 0.9956, AUPR_OUT: 0.9986\n",
            "SRC->TAR2:      AUROC: 0.9975, FPR95: 0.0033, AUPR_IN: 0.9956, AUPR_OUT: 0.9986\n",
            "SRC->TAR1+TAR2: AUROC: 0.9975, FPR95: 0.0033, AUPR_IN: 0.9912, AUPR_OUT: 0.9991\n",
            "to spreadsheet: 0.997538888888889,0.0033333333333333335,0.9955621156252624,0.9985828544061303,0.997538888888889,0.0033333333333333335,0.9955621156252624,0.9985828544061303,0.997538888888889,0.0033333333333333335,0.9911854564885755,0.9991001428957633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(defect_chairs_distort_feats)\n",
        "print(defect_chairs_remove_parts_feats)\n",
        "print(defect_chairs_scale_feats)\n",
        "print(defect_chairs_add_noise_feats)\n",
        "print(defect_chairs_asymmetrical_feats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lit4f8DgRhab",
        "outputId": "d37173d2-d4be-4442-d06d-b77f4be5d57a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-7.4809, -2.2340, -5.3724,  ..., -4.1800, -8.8784, 10.6148]],\n",
            "\n",
            "        [[-7.4849, -2.2236, -5.3625,  ..., -4.1578, -8.8651, 10.5940]],\n",
            "\n",
            "        [[-7.4862, -2.2205, -5.3602,  ..., -4.1464, -8.8596, 10.5852]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-7.6005, -1.6649, -5.1331,  ..., -3.3893, -8.3226,  9.4985]],\n",
            "\n",
            "        [[-7.5922, -1.6652, -5.1319,  ..., -3.3835, -8.3146,  9.4883]],\n",
            "\n",
            "        [[-7.5914, -1.6591, -5.1296,  ..., -3.3696, -8.3065,  9.4688]]],\n",
            "       device='cuda:0')\n",
            "tensor([[[-6.0541, -2.3324, -5.2111,  ..., -3.0864, -7.5346,  8.8240]],\n",
            "\n",
            "        [[-6.0003, -2.3947, -5.1985,  ..., -3.0957, -7.5401,  8.8404]],\n",
            "\n",
            "        [[-8.6495, -1.1699, -4.8606,  ..., -1.4596, -8.4527,  7.8620]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-8.4532, -1.5376, -5.0058,  ..., -3.8911, -9.0175, 10.3888]],\n",
            "\n",
            "        [[-8.7176, -1.0993, -4.7942,  ..., -1.3544, -8.4703,  7.7208]],\n",
            "\n",
            "        [[-8.7287, -1.0580, -4.7772,  ..., -1.3054, -8.4648,  7.6402]]],\n",
            "       device='cuda:0')\n",
            "tensor([[[-7.5912, -1.6592, -5.1294,  ..., -3.3693, -8.3063,  9.4686]],\n",
            "\n",
            "        [[-7.5915, -1.6591, -5.1296,  ..., -3.3692, -8.3064,  9.4685]],\n",
            "\n",
            "        [[-7.5918, -1.6589, -5.1295,  ..., -3.3691, -8.3065,  9.4684]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-7.5917, -1.6590, -5.1295,  ..., -3.3692, -8.3066,  9.4687]],\n",
            "\n",
            "        [[-7.5917, -1.6590, -5.1295,  ..., -3.3692, -8.3066,  9.4687]],\n",
            "\n",
            "        [[-7.5917, -1.6590, -5.1295,  ..., -3.3692, -8.3066,  9.4687]]],\n",
            "       device='cuda:0')\n",
            "tensor([[[-7.5917, -1.6590, -5.1295,  ..., -3.3692, -8.3066,  9.4687]],\n",
            "\n",
            "        [[-7.5917, -1.6590, -5.1295,  ..., -3.3692, -8.3066,  9.4687]],\n",
            "\n",
            "        [[-7.5917, -1.6590, -5.1295,  ..., -3.3692, -8.3066,  9.4687]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-7.5917, -1.6590, -5.1295,  ..., -3.3692, -8.3066,  9.4687]],\n",
            "\n",
            "        [[-7.5917, -1.6590, -5.1295,  ..., -3.3692, -8.3066,  9.4687]],\n",
            "\n",
            "        [[-7.5917, -1.6590, -5.1295,  ..., -3.3692, -8.3066,  9.4687]]],\n",
            "       device='cuda:0')\n",
            "tensor([[[-7.2482, -0.5390, -3.8559,  ..., -3.2043, -7.1437,  7.9693]],\n",
            "\n",
            "        [[-7.9239, -1.4219, -4.8966,  ..., -2.7418, -8.2236,  8.9562]],\n",
            "\n",
            "        [[-7.4004, -0.3066, -3.5233,  ..., -2.6127, -6.9983,  7.3030]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-7.0782, -2.4202, -5.9043,  ..., -3.6748, -8.6593,  9.8734]],\n",
            "\n",
            "        [[-7.2053, -2.5016, -6.0912,  ..., -4.4910, -9.1251, 10.6030]],\n",
            "\n",
            "        [[-7.1480, -1.6086, -5.0688,  ..., -3.8326, -8.0620,  9.4799]]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(src_feats.shape)\n",
        "print(defect_chairs_remove_parts_feats.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-FiKv48ScOE",
        "outputId": "9105c8ec-883c-4971-807b-1efc661acc90"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([300, 1, 7])\n",
            "torch.Size([300, 1, 7])\n"
          ]
        }
      ]
    }
  ]
}